{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Available methods are the followings:\n",
    "[1] AssoRuleMining\n",
    "[2] define_dtype\n",
    "[3] discretize\n",
    "[4] RuleToFeature\n",
    "[5] print_stats\n",
    "[6] print_rule\n",
    "[7] evaluate_rules\n",
    "[8] create_rule\n",
    "[9] GetDecisionPaths\n",
    "[10] TreeRuleMining\n",
    "\n",
    "Authors: Danusorn Sitdhirasdr <danusorn.si@gmail.com>\n",
    "versionadded:: 31-01-2023\n",
    "\n",
    "'''\n",
    "import pandas as pd, numpy as np, time, os\n",
    "from collections import namedtuple\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import multiprocessing, numbers\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "from scipy.sparse import csc_matrix as csc, isspmatrix_csc\n",
    "import sklearn\n",
    "from sklearn.metrics import (confusion_matrix, f1_score)\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              ExtraTreesClassifier, \n",
    "                              RandomForestRegressor, \n",
    "                              ExtraTreesRegressor)\n",
    "from sklearn.tree import (DecisionTreeRegressor,\n",
    "                          DecisionTreeClassifier, \n",
    "                          _tree)\n",
    "from sklearn.utils import (check_random_state,\n",
    "                           check_array)\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "__all__  = [\"AssoRuleMining\", \n",
    "            \"define_dtype\",\n",
    "            \"discretize\",\n",
    "            \"RuleToFeature\",\n",
    "            \"print_stats\",\n",
    "            \"print_rule\", \n",
    "            \"evaluate_rules\",\n",
    "            \"create_rule\",\n",
    "            \"GetDecisionPaths\",\n",
    "            \"rule_alert\",\n",
    "            \"TreeRuleMining\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danusorn.s\\AppData\\Local\\Temp\\ipykernel_20252\\1375801020.py:1: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(sklearn.__version__) < LooseVersion(\"0.17\"):\n"
     ]
    }
   ],
   "source": [
    "if LooseVersion(sklearn.__version__) < LooseVersion(\"0.17\"):\n",
    "    raise Exception(\"TreeExplainer requires scikit-learn 0.17 or later\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnamedtuple(x):\n",
    "    t = type(x)\n",
    "    b = t.__bases__\n",
    "    if len(b) != 1 or b[0] != tuple: return False\n",
    "    f = getattr(t, '_fields', None)\n",
    "    if not isinstance(f, tuple): return False\n",
    "    return all(type(n)==str for n in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interval(Param, Value, dtype=int, left=None, right=None, closed=\"both\"):\n",
    "    '''\n",
    "    '''\n",
    "    Options = {\"left\"    : (np.greater_equal, np.less), # a<=x<b\n",
    "               \"right\"   : (np.greater, np.less_equal), # a<x<=b\n",
    "               \"both\"    : (np.greater_equal, np.less_equal), # a<=x<=b\n",
    "               \"neither\" : (np.greater, np.less)} # a<x<b\n",
    "    \n",
    "    f0, f1 = Options[closed]\n",
    "    c0 = \"[\" if f0.__name__.find(\"eq\")>-1 else \"(\" \n",
    "    c1 = \"]\" if f1.__name__.find(\"eq\")>-1 else \")\"\n",
    "    v0 = \"-∞\" if left is None else str(dtype(left))\n",
    "    v1 = \"+∞\" if right is None else str(dtype(right))\n",
    "    if left  is None: left  = -np.inf\n",
    "    if right is None: right = +np.inf\n",
    "    interval = \", \".join([c0+v0,v1+c1])\n",
    "    tuples = (Param, dtype.__name__, interval, Value)\n",
    "    err_msg = \"%s must be %s or in %s, got %s \" % tuples    \n",
    "    \n",
    "    if isinstance(Value, dtype):\n",
    "        if not (f0(Value, left) & f1(Value, right)):\n",
    "            raise ValueError(err_msg)\n",
    "    else: raise ValueError(err_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StrOptions(Options, Param, Value, dtype=str):\n",
    "    '''\n",
    "    '''\n",
    "    if Value not in Options:\n",
    "        opts = f'{Param} ({dtype.__name__}) must be either '\n",
    "        for n,s in enumerate(Options):\n",
    "            if n<len(Options)-1: opts += f'\"{s}\", '\n",
    "            else: opts += f' or \"{s}\" , got %s'\n",
    "        raise ValueError(opts % Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tree_paths(tree, node_id=0):\n",
    "    \n",
    "    '''\n",
    "    Determine all paths through the tree as list of node-ids.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : sklearn.tree._tree.Tree object\n",
    "        sklearn Tree \n",
    "    \n",
    "    node_id : int, default=0\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    paths : list of paths\n",
    "        \n",
    "    '''\n",
    "    if node_id == _tree.TREE_LEAF:\n",
    "        raise ValueError(\"Invalid node_id %s\" % _tree.TREE_LEAF)\n",
    "\n",
    "    left_child  = tree.children_left[node_id]\n",
    "    right_child = tree.children_right[node_id]\n",
    "\n",
    "    if left_child != _tree.TREE_LEAF:\n",
    "        left_paths  = find_tree_paths(tree, left_child)\n",
    "        right_paths = find_tree_paths(tree, right_child)\n",
    "        \n",
    "        for path in left_paths: path.append(node_id)\n",
    "        for path in right_paths: path.append(node_id)\n",
    "        paths = left_paths + right_paths\n",
    "    else: paths = [[node_id]]\n",
    "        \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_decision_path(Tree, feature_names=None, tree_id=0):\n",
    "    \n",
    "    '''\n",
    "    It retrieves all decision paths contained in sklearn base \n",
    "    estimator (DecisionTreeRegressor or DecisionTreeClassifier). \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Tree : estimator object\n",
    "        sklearn base estimator i.e. DecisionTreeRegressor or \n",
    "        DecisionTreeClassifier.\n",
    "        \n",
    "    feature_names : list of str, default=None\n",
    "        Names of each of the features. If None, generic names will be \n",
    "        used (\"X[0]\"\", \"X[1]\"\", …, \"X[n]\").\n",
    "    \n",
    "    tree_id : int, default=0\n",
    "        The id number of tree. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    decision_paths : dict of collections.namedtuple\n",
    "        A dict with keys as \"tree{tree_id}_{leaf_node_id}\", and \n",
    "        namedtuple (\"Results\") as values, whose fields are as follows:\n",
    "    \n",
    "        Field        Description\n",
    "        -----        -----------\n",
    "        metric**     Evaluating metric \n",
    "        operator**   Relationship between rules \n",
    "        n_targets    Number of targets \n",
    "        n_samples**  Number of samples \n",
    "        p_target     % target i.e. n_targets/n_samples[0]\n",
    "        p_sample**   % sample i.e. n_samples/n_samples[0] \n",
    "        recall       Recall score\n",
    "        precision    Precision score\n",
    "        f1_score     F1 score\n",
    "        impurity**   impurity resulted from selected measure \n",
    "        rule**       A list of splitting conditions \n",
    "        \n",
    "        Note: all outputs are arranged according to node id (from root to \n",
    "              leaf node). Fields with ** are only available when sklearn \n",
    "              base estimator is DecisionTreeRegressor.\n",
    "        \n",
    "    '''\n",
    "    # Check base estimator\n",
    "    if not isinstance(Tree, (DecisionTreeClassifier,\n",
    "                             DecisionTreeRegressor)): \n",
    "        raise ValueError(\"Wrong model type. Base learner needs to \"\n",
    "                         \"be either DecisionTreeRegressor \"\n",
    "                         \"DecisionTreeClassifier.\")\n",
    "    \n",
    "    # Check whether `Tree` is fitted.\n",
    "    check_is_fitted(Tree, msg=\"This instance is not fitted yet. \"\n",
    "                    \"Call `fit` with appropriate arguments before \"\n",
    "                    \"using this estimator.\")\n",
    "    \n",
    "    # Default feature names i.e. X[n]\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"X[{n}]\" for n in \n",
    "                         range(Tree.tree_.n_features)]\n",
    "\n",
    "    # Tree attributes\n",
    "    features = Tree.tree_.feature\n",
    "    node_samples = Tree.tree_.n_node_samples\n",
    "    thresholds = Tree.tree_.threshold\n",
    "    left_nodes = Tree.tree_.children_left\n",
    "    right_nodes = Tree.tree_.children_right\n",
    "    leaf_nodes = right_nodes == left_nodes\n",
    "    tot_samples = node_samples[0]\n",
    "\n",
    "    # Get all paths from tree and order node.\n",
    "    paths = find_tree_paths(Tree.tree_)\n",
    "    for path in paths: path.reverse()\n",
    "\n",
    "    # Map leaves to paths.\n",
    "    leaf_to_path = dict((path[-1], path) for path in paths)\n",
    "\n",
    "    # Remove the single-dimensional inner arrays.\n",
    "    # values : number of sample wrt. class in each node.\n",
    "    values = Tree.tree_.value.squeeze(axis=1)\n",
    "\n",
    "    # Reshape if squeezed into a single float\n",
    "    values = np.array([values]) if len(values.shape) == 0 else values\n",
    "\n",
    "    # Determine rule for each decision path\n",
    "    rule = dict()\n",
    "    for leaf,path in leaf_to_path.items():\n",
    "        rule.update({leaf:[]})\n",
    "        for n0,n1 in zip(path[:-1],path[1:]):\n",
    "            sign = \"<=\" if n1 in left_nodes else \">\"\n",
    "            rule[leaf].append((feature_names[features[n0]], \n",
    "                               sign, thresholds[n0])) \n",
    "\n",
    "    # Returning results\n",
    "    decision_paths = dict()\n",
    "    if isinstance(Tree, DecisionTreeClassifier): \n",
    "        \n",
    "        for leaf,path in leaf_to_path.items():\n",
    "            n_targets = values[path,:][:,1]\n",
    "            n_samples = node_samples[path]\n",
    "            precision = n_targets/n_samples\n",
    "            recall = n_targets/n_targets[0]\n",
    "  \n",
    "            values_ = {\"metric\"    : Tree.criterion,\n",
    "                       \"operator\"  : \"and\",\n",
    "                       \"n_targets\" : n_targets.astype(int), \n",
    "                       \"n_samples\" : n_samples.astype(int), \n",
    "                       \"p_target\"  : n_targets/tot_samples, \n",
    "                       \"p_sample\"  : n_samples/tot_samples, \n",
    "                       \"recall\"    : recall, \n",
    "                       \"precision\" : precision, \n",
    "                       \"f1_score\"  : (2 * precision * recall / \n",
    "                                      np.fmax(precision + recall, 1)), \n",
    "                       \"impurity\"  : Tree.tree_.impurity[path], \n",
    "                       \"rule\"      : rule[leaf]}\n",
    "            decision_paths[f\"T{tree_id}-{leaf}\"] = \\\n",
    "            namedtuple(\"Results\", values_.keys())(**values_)\n",
    "        \n",
    "    elif isinstance(Tree, DecisionTreeRegressor):\n",
    "        \n",
    "        for leaf,path in leaf_to_path.items():\n",
    "            n_samples = node_samples[path]\n",
    "       \n",
    "            values_ = {\"metric\"    : Tree.criterion,\n",
    "                       \"operator\"  : \"and\",\n",
    "                       \"n_samples\" : n_samples.astype(int), \n",
    "                       \"p_sample\"  : n_samples/tot_samples,  \n",
    "                       \"impurity\"  : Tree.tree_.impurity[path], \n",
    "                       \"rule\"      : rule[leaf]}\n",
    "            decision_paths[f\"T{tree_id}-{leaf}\"] = \\\n",
    "            namedtuple(\"Results\", values_.keys())(**values_)\n",
    "            \n",
    "    return decision_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDecisionPaths:\n",
    "    \n",
    "    '''\n",
    "    It retrieves all decision paths contained in sklearn base \n",
    "    estimator i.e. DecisionTreeClassifier or DecisionTreeRegressor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_precision : float, default=1e-4\n",
    "        The minimum precision required to be at a leaf node. This is\n",
    "        relevant when base estimator is DecisionTreeClassifier.\n",
    "        \n",
    "    min_recall : float, default=1e-4\n",
    "        The minimum recall required to be at a leaf node. This is\n",
    "        relevant when base estimator is DecisionTreeClassifier.\n",
    "        \n",
    "    min_f1_score : float, default=1e-4\n",
    "        The minimum f1-score required to be at a leaf node. This is\n",
    "        relevant when base estimator is DecisionTreeClassifier.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    decision_paths : dict of collections.namedtuple\n",
    "        A dict with keys as \"tree{tree_id}_{leaf_node_id}\", and \n",
    "        namedtuple (\"Results\") as values, whose fields are as follows:\n",
    "\n",
    "        Field        Description\n",
    "        -----        -----------\n",
    "        metric**     Evaluating metric \n",
    "        operator**   Relationship between rules \n",
    "        n_targets    Number of targets \n",
    "        n_samples**  Number of samples \n",
    "        p_target     % target i.e. n_targets/n_samples[0]\n",
    "        p_sample**   % sample i.e. n_samples/n_samples[0] \n",
    "        recall       Recall score\n",
    "        precision    Precision score\n",
    "        f1_score     F1 score\n",
    "        impurity**   impurity resulted from selected measure \n",
    "        rule**       A list of splitting conditions \n",
    "\n",
    "        Note: all outputs are arranged according to node id (from root to \n",
    "              leaf node). Fields with ** are only available when sklearn \n",
    "              base estimator is DecisionTreeRegressor.\n",
    "\n",
    "    info : dict of numpy (masked) ndarrays\n",
    "        A dict with keys as column headers. It can be imported into a \n",
    "        pandas DataFrame, whose fields are as follows:\n",
    "\n",
    "        Field       Description\n",
    "        -----       -----------\n",
    "        key**       \"T{tree_id}-{leaf_node_id}\"\n",
    "        depth**     The depth of the decision path\n",
    "        n_targets   Number of targets at leaf node\n",
    "        n_samples** Number of samples at leaf node\n",
    "        recalls     Recall scores\n",
    "        precisions  Precision scores\n",
    "        f1_scores   F1 scores\n",
    "        impurity**  impurity resulted from selected measure\n",
    "\n",
    "        Note: Fields with ** are only available when sklearn base \n",
    "              estimator is DecisionTreeRegressor.\n",
    "                  \n",
    "    '''\n",
    "    classifiers = (DecisionTreeClassifier, \n",
    "                   RandomForestClassifier, \n",
    "                   ExtraTreesClassifier)\n",
    "    regressors  = (DecisionTreeRegressor , \n",
    "                   RandomForestRegressor ,\n",
    "                   ExtraTreesRegressor)\n",
    "        \n",
    "    def __init__(self, min_precision=1e-4, min_recall=1e-4, \n",
    "                 min_f1_score=1e-4):\n",
    "        \n",
    "        self.__PositiveFloat__(\"min_precision\", min_precision)\n",
    "        self.__PositiveFloat__(\"min_recall\", min_recall)\n",
    "        self.__PositiveFloat__(\"min_f1_score\", min_f1_score)\n",
    "        self.min_precision = min_precision\n",
    "        self.min_recall = min_recall\n",
    "        self.min_f1_score = min_f1_score\n",
    "        \n",
    "    def __PositiveFloat__(self, name, value):\n",
    "        \n",
    "        err_msg = \"%s must be positive float or in \"\\\n",
    "        \"(0., 1.], got %s\" % (name, value)\n",
    "        if isinstance(value, float):\n",
    "            if not 0. < value <= 1.: \n",
    "                raise ValueError(err_msg)\n",
    "        else: raise ValueError(err_msg)\n",
    "    \n",
    "    def fit(self, estimator, feature_names=None):\n",
    "        \n",
    "        '''\n",
    "        Fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : fitted estimator object\n",
    "            The object must be the following scikit-learn estimator:\n",
    "            - DecisionTreeClassifier\n",
    "            - ExtraTreeClassifier\n",
    "            - RandomForestClassifier\n",
    "            - DecisionTreeRegressor \n",
    "            - RandomForestRegressor\n",
    "            - ExtraTreesRegressor\n",
    "        \n",
    "        feature_names : list of str, default=None\n",
    "            Names of each of the features. If None, generic names will be \n",
    "            used (\"X[0]\"\", \"X[1]\"\", …, \"X[n]\").\n",
    " \n",
    "        Attributes\n",
    "        ----------\n",
    "        decision_paths : dict of collections.namedtuple\n",
    "            A dict with keys as \"tree{tree_id}_{leaf_node_id}\", and \n",
    "            namedtuple (\"Results\") as values, whose fields are as follows:\n",
    "\n",
    "            Field        Description\n",
    "            -----        -----------\n",
    "            metric**     Evaluating metric \n",
    "            operator**   Relationship between rules \n",
    "            n_targets    Number of targets \n",
    "            n_samples**  Number of samples \n",
    "            p_target     % target i.e. n_targets/n_samples[0]\n",
    "            p_sample**   % sample i.e. n_samples/n_samples[0] \n",
    "            recall       Recall score\n",
    "            precision    Precision score\n",
    "            f1_score     F1 score\n",
    "            impurity**   impurity resulted from selected measure \n",
    "            rule**       A list of splitting conditions \n",
    "\n",
    "            Note: all outputs are arranged according to node id (from root to \n",
    "                  leaf node). Fields with ** are only available when sklearn \n",
    "                  base estimator is DecisionTreeRegressor.\n",
    "        \n",
    "        info : dict of numpy (masked) ndarrays\n",
    "            A dict with keys as column headers. It can be imported into a \n",
    "            pandas DataFrame, whose fields are as follows:\n",
    "\n",
    "            Field       Description\n",
    "            -----       -----------\n",
    "            key**       \"T{tree_id}-{leaf_node_id}\"\n",
    "            depth**     The depth of the decision path\n",
    "            n_targets   Number of targets at leaf node\n",
    "            n_samples** Number of samples at leaf node\n",
    "            recalls     Recall scores\n",
    "            precisions  Precision scores\n",
    "            f1_scores   F1 scores\n",
    "            impurity**  impurity resulted from selected measure\n",
    "            \n",
    "            Note: Fields with ** are only available when sklearn base \n",
    "                  estimator is DecisionTreeRegressor.\n",
    "            \n",
    "        '''\n",
    "        # Only single response variable supported (binary)\n",
    "        if estimator.n_outputs_ > 1:\n",
    "            raise ValueError(\"Multilabel classification trees not supported\")\n",
    "        \n",
    "        if isinstance(estimator, self.classifiers): \n",
    "            self.estimator = estimator\n",
    "            self.is_classifer = True\n",
    "        elif isinstance(estimator, self.regressors): \n",
    "            self.estimator = estimator\n",
    "            self.is_classifer = False\n",
    "        else: raise ValueError(\"Wrong model type. Estimator needs to \"\n",
    "                               \"be sklearn mdoel whose base learner is\"\n",
    "                               \"either DecisionTreeRegressor or\" \n",
    "                               \"DecisionTreeClassifier.\")\n",
    "        \n",
    "        if isinstance(self.estimator, (DecisionTreeClassifier,\n",
    "                                       DecisionTreeRegressor)):\n",
    "            self.decision_paths = find_decision_path(self.estimator, \n",
    "                                                     feature_names, 0)\n",
    "        else:    \n",
    "            self.decision_paths = dict()\n",
    "            for n,Tree in enumerate(self.estimator):\n",
    "                args = (Tree, feature_names, n)\n",
    "                decision_paths = find_decision_path(*args)\n",
    "                self.decision_paths.update(find_decision_path(*args))     \n",
    "    \n",
    "        self.__FilterPath__()\n",
    "        self.__CreateInfo__()\n",
    "        try: self.n_paths = len(self.info[\"key\"])\n",
    "        except: self.n_paths = 0\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __FilterPath__(self):\n",
    "        \n",
    "        if self.is_classifer: \n",
    "            remove_keys = []\n",
    "            for key in self.decision_paths:\n",
    "                rule  = self.decision_paths[key]\n",
    "                cond  = self.min_precision <= rule.precision[-1]    \n",
    "                cond &= self.min_recall <= rule.recall[-1]\n",
    "                cond &= self.min_f1_score <= rule.f1_score[-1]\n",
    "                if not cond: remove_keys.append(key)\n",
    "            \n",
    "            if len(remove_keys)>0:\n",
    "                for key in remove_keys:\n",
    "                    _ = self.decision_paths.pop(key)\n",
    "    \n",
    "    def __CreateInfo__(self):\n",
    "        \n",
    "        '''\n",
    "        Summary of all decision paths.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        info : dict of numpy (masked) ndarrays\n",
    "            A dict with keys as column headers. It can be imported into a \n",
    "            pandas DataFrame, whose fields are as follows:\n",
    "\n",
    "            Field       Description\n",
    "            -----       -----------\n",
    "            key**       \"T{tree_id}-{leaf_node_id}\"\n",
    "            depth**     The depth of the decision path\n",
    "            n_targets   Number of targets at leaf node\n",
    "            n_samples** Number of samples at leaf node\n",
    "            recalls     Recall scores\n",
    "            precisions  Precision scores\n",
    "            f1_scores   F1 scores\n",
    "            impurity**  impurity resulted from selected measure\n",
    "            \n",
    "            Note: Fields with ** are only available when sklearn base \n",
    "                  estimator is DecisionTreeRegressor.\n",
    "                  \n",
    "        '''\n",
    "        data = []\n",
    "        if self.is_classifer:\n",
    "            for var,a in self.decision_paths.items():\n",
    "                data += [{\"key\"        : var, \n",
    "                          \"depth\"      : len(a.rule),\n",
    "                          \"n_targets\"  : a.n_targets[-1], \n",
    "                          \"n_samples\"  : a.n_samples[-1], \n",
    "                          \"f1_score\"   : a.f1_score[-1],\n",
    "                          \"recall\"     : a.recall[-1], \n",
    "                          \"precision\"  : a.precision[-1],\n",
    "                          \"impurity\"   : a.impurity[-1]}]\n",
    "        else:\n",
    "            for var,a in self.decision_paths.items():\n",
    "                data += [{\"key\"        : var, \n",
    "                          \"depth\"      : len(a.rule),\n",
    "                          \"n_samples\"  : a.n_samples[-1], \n",
    "                          \"impurity\"   : a.impurity[-1]}]\n",
    "                \n",
    "        self.info = pd.DataFrame(data).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treebased_binning(x, y=None, min_samples=0.05, random_state=0):\n",
    "    \n",
    "    '''\n",
    "    Function to calculate only the edges of the bins used by the \n",
    "    histogram function using sklearn tree-base learner i.e.\n",
    "    DecisionTreeClassifier or DecisionTreeRegressor (when y is None).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like of shape (n_samples,)\n",
    "        The input samples.\n",
    "\n",
    "    y : array-like of shape (n_samples,), default=None\n",
    "        The target values (class labels) as integers.\n",
    "\n",
    "    min_samples : int or float, default=1\n",
    "        The minimum number of samples required to be at a leaf node. \n",
    "        - If int, then consider min_samples as the minimum number.\n",
    "        - If float, then min_samples is a fraction and ceil\n",
    "          (min_samples * n_samples) are the minimum number of samples \n",
    "          for each node.\n",
    "          \n",
    "    random_state : int, default=0\n",
    "        Controls the randomness of generating y with a uniform \n",
    "        distribution. This is relevant with y is not provided.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bin_edges : array of dtype float\n",
    "        The edges to pass into np.histogram\n",
    "        \n",
    "    '''\n",
    "    n_samples = len(x)\n",
    "    x = np.array(x).reshape(-1,1)\n",
    "    \n",
    "    msg = (\"min_samples must be at least 1 or \"\n",
    "           \"in (0, 0.5], got {}\".format)\n",
    "    if isinstance(min_samples, float):\n",
    "        if not 0.0 < min_samples <= 0.5:\n",
    "            raise ValueError(msg(min_samples))\n",
    "        min_samples = int(np.ceil(min_samples * n_samples))     \n",
    "    elif isinstance(min_samples, int):\n",
    "        if not 0 < min_samples:\n",
    "            raise ValueError(msg(min_samples))\n",
    "    else: raise ValueError(msg(min_samples))\n",
    "    \n",
    "    # Initial parameters\n",
    "    criterion = \"squared_error\" if y is None else \"gini\"\n",
    "    kwds = dict(criterion=criterion,\n",
    "                min_samples_leaf=min_samples,\n",
    "                max_depth=None,\n",
    "                max_features=None, \n",
    "                random_state=None)\n",
    "        \n",
    "    # Fit base learner\n",
    "    if y is None:\n",
    "        # Get RandomState singleton used by np.random\n",
    "        rnd = check_random_state(random_state)\n",
    "        y = rnd.uniform(size=len(x))\n",
    "        Tree = DecisionTreeRegressor(**kwds).fit(x, y)\n",
    "    else: Tree  = DecisionTreeClassifier({**kwds,}).fit(x, y)\n",
    "        \n",
    "    # Find decision paths in Tree\n",
    "    paths, bin_edges = GetDecisionPaths().fit(Tree), []\n",
    "    for value in paths.decision_paths.values():\n",
    "        if len(value.rule)>0: bin_edges.append(value.rule[-1][-1])\n",
    "    return np.r_[-np.inf, np.unique(bin_edges), np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeRuleMining:\n",
    "    \n",
    "    '''\n",
    "    For every iteration, this class implements sklearn tree-based \n",
    "    classifier to determine path (or rule) that satisfy constraints\n",
    "    such as precision or recall. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object\n",
    "        sklearn estimator i.e. DecisionTreeClassifier or \n",
    "        RandomForestClassifier or ExtraTreesClassifier.\n",
    "        \n",
    "    min_precision : float, default=1e-4\n",
    "        The minimum precision required to be at a leaf node. \n",
    "    \n",
    "    min_recall : float, default=1e-4\n",
    "        The minimum recall required to be at a leaf node. \n",
    "        \n",
    "    min_f1_score : float, default=1e-4\n",
    "        The minimum f1-score required to be at a leaf node. \n",
    "        \n",
    "    max_iter : int, default=10\n",
    "        Maximum number of iterations taken for a single run.\n",
    "        \n",
    "    metric : str, default=\"f1-score\"\n",
    "        The function to evaluate the quality of rule. Supported \n",
    "        criteria are \"recall\" for the recall, \"precision\" for the \n",
    "        precision, and \"f1-score\" for the balanced F-score.\n",
    "    \n",
    "    cal_max_depth : bool, default=False\n",
    "        If True, maximum depth is calculated for each iteration. \n",
    "        Otherwise it uses default max_depth. This is relevant when \n",
    "        \"exclude\" is True.\n",
    "        \n",
    "    exclude : bool, default=True\n",
    "        If True, after each iteration samples under previously selected\n",
    "        leaf node (path) are removed from the training set. If False,\n",
    "        it changes target to non-target i.e. 1 to 0 while keeping the \n",
    "        sample size the same.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    rules : dict of collections.namedtuple\n",
    "        A dict with keys as \"Rule{n_iter}\", and namedtuple (\"Results\") \n",
    "        as values, whose fields are as follows:\n",
    "\n",
    "        Field        Description\n",
    "        -----        -----------\n",
    "        metric       Evaluating metric \n",
    "        operator     Relationship between rules \n",
    "        n_targets    Number of targets \n",
    "        n_samples    Number of samples \n",
    "        p_target     % target i.e. n_targets/n_samples[0]\n",
    "        p_sample     % sample i.e. n_samples/n_samples[0] \n",
    "        recall       Recall score\n",
    "        precision    Precision score\n",
    "        f1_score     F1 score\n",
    "        impurity     impurity resulted from selected measure \n",
    "        rule         A list of splitting conditions \n",
    "\n",
    "        Note: all outputs are arranged according to node id (from root \n",
    "              to leaf node).\n",
    "              \n",
    "    '''\n",
    "    classifiers = (DecisionTreeClassifier, \n",
    "                   RandomForestClassifier, \n",
    "                   ExtraTreesClassifier)\n",
    "    metric = [\"precision\", \"recall\", \"f1-score\"]\n",
    "   \n",
    "    def __init__(self, estimator=None, min_precision=1e-4, \n",
    "                 min_recall=1e-4, min_f1_score=1e-4, max_iter=10, \n",
    "                 metric=\"f1-score\", cal_max_depth=False, exclude=True):\n",
    "        \n",
    "        if estimator is not None:\n",
    "            # Check base estimator\n",
    "            if not isinstance(estimator, self.classifiers): \n",
    "                raise ValueError(\"Wrong model type. Base learner needs to \"\n",
    "                                 \"be DecisionTreeClassifier.\")\n",
    "            # Clone estimator and get initial hyperparameters\n",
    "            self.estimator = sklearn.base.clone(estimator)\n",
    "        else: self.estimator = DecisionTreeClassifier()\n",
    "        \n",
    "        # Validate parameters\n",
    "        args = (float, 0., 1., \"right\")\n",
    "        Interval(\"min_precision\", min_precision, *args)\n",
    "        Interval(\"min_recall\", min_recall, *args)\n",
    "        Interval(\"min_f1_score\", min_f1_score, *args)\n",
    "        Interval(\"max_iter\", max_iter, int, 0, None, \"right\")\n",
    "        StrOptions(self.metric, \"metric\", metric)\n",
    "        StrOptions([True, False], \"cal_max_depth\", cal_max_depth, bool)\n",
    "        StrOptions([True, False], \"exclude\", exclude, bool)\n",
    "\n",
    "        # Store parameters\n",
    "        self.params = estimator.get_params()\n",
    "        self.kwargs = {\"min_precision\" : min_precision, \n",
    "                       \"min_recall\"    : min_recall, \n",
    "                       \"min_f1_score\"  : min_f1_score}\n",
    "        self.max_iter = max_iter\n",
    "        self.metric = metric.replace(\"-\",\"_\")\n",
    "        self.cal_max_depth = cal_max_depth\n",
    "        self.exclude = exclude\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        '''\n",
    "        Fit the model from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, shape of (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target values (class labels) as integers.\n",
    "       \n",
    "        Attributes\n",
    "        ----------\n",
    "        rules : dict of collections.namedtuple\n",
    "            A dict with keys as \"Rule{n_iter}\", and namedtuple (\"Results\") \n",
    "            as values, whose fields are as follows:\n",
    "\n",
    "            Field        Description\n",
    "            -----        -----------\n",
    "            metric       Evaluating metric \n",
    "            operator     Relationship between rules \n",
    "            n_targets    Number of targets \n",
    "            n_samples    Number of samples \n",
    "            p_target     % target i.e. n_targets/n_samples[0]\n",
    "            p_sample     % sample i.e. n_samples/n_samples[0] \n",
    "            recall       Recall score\n",
    "            precision    Precision score\n",
    "            f1_score     F1 score\n",
    "            impurity     impurity resulted from selected measure \n",
    "            rule         A list of splitting conditions \n",
    "        \n",
    "            Note: all outputs are arranged according to node id (from root \n",
    "                  to leaf node).\n",
    "                  \n",
    "        '''\n",
    "         # Initialize widgets\n",
    "        w1 = widgets.HTMLMath(value='Calculating . . .')\n",
    "        w2 = widgets.HTMLMath(value='')\n",
    "        w = widgets.HBox([w1, w2])\n",
    "        display(w); time.sleep(1)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        start = time.time()\n",
    "        params = self.params\n",
    "        self.rules = dict()\n",
    "        n_iters = 1\n",
    "        \n",
    "        # Inputs\n",
    "        features = list(X)\n",
    "        X, y = X.copy(), np.array(y).ravel().copy()\n",
    "        n_samples, n_targets = len(X), sum(y)\n",
    "        use = np.ones(n_samples).astype(bool)\n",
    "        \n",
    "        # widget inputs\n",
    "        t1 = 'Calculating . . . Iteration : {:,d}/{:,d}'.format\n",
    "        t2 = ', Number of remaining targets : {:,d} ({:.0%})'.format\n",
    "        w1.value = t1(0, self.max_iter)\n",
    "    \n",
    "        while True:\n",
    "            \n",
    "            # Break when there is no sample or no target left or\n",
    "            # number of iterations exceeds limit.\n",
    "            if (sum(use)==0) or (y[use].sum()==0) or \\\n",
    "            (n_iters > self.max_iter): break\n",
    "            w1.value = t1(n_iters, self.max_iter)\n",
    "            w2.value = t2(sum(y[use]), sum(y[use])/n_targets)\n",
    "            \n",
    "            # Update max_depth\n",
    "            if self.cal_max_depth:\n",
    "                params.update({\"max_depth\": np.ceil(np.log2(sum(use)))})\n",
    "            \n",
    "            # Fit model with updated parameters\n",
    "            Tree = self.estimator.set_params(**params).fit(X[use], y[use])\n",
    "            paths = GetDecisionPaths(**self.kwargs).fit(Tree, features)\n",
    "            \n",
    "            # Stop when there is no desicion path\n",
    "            if len(paths.decision_paths.keys())==0: break\n",
    "            \n",
    "            # Find nth path that optimizes selected metric\n",
    "            k_max = np.argmax(paths.info[self.metric])\n",
    "            best_path = paths.info[\"key\"][k_max]\n",
    "            best_path = paths.decision_paths[best_path]\n",
    "            self.rules[f\"Rule_{n_iters}\"] = best_path\n",
    "            \n",
    "            # Update remaining instances.\n",
    "            alerts = rule_alert(X, best_path)\n",
    "            if self.exclude:\n",
    "                use = np.where(alerts, False, use)\n",
    "            else: y = np.where(alerts, 0, y)\n",
    "            n_iters += 1\n",
    "        \n",
    "        w1.value = 'Complete' \n",
    "        r_time = time.gmtime(time.time() - start)\n",
    "        r_time = time.strftime(\"%H:%M:%S\", r_time)\n",
    "        w2.value = '. . . Total running time: {}'.format(r_time)\n",
    "        \n",
    "        self.n_rules = len(self.rules.keys())\n",
    "        if self.n_rules==0:\n",
    "            warn_msg = (\"The algorithm can not find any path that \"\n",
    "                        \"satisfies constraints. Please consider \"\n",
    "                        \"relaxing one or more of the constraints.\")\n",
    "            warnings.warn(warn_msg)\n",
    "           \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, n_rules=None):\n",
    "        \n",
    "        '''\n",
    "        Apply rules on X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, shape of (n_samples, n_features)\n",
    "            The input samples.\n",
    "        \n",
    "        n_rules : int, default=None\n",
    "            Number of rules to be applied. If None, all rules are applied.\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        X_rules : pd.DataFrame, shape of (n_samples, n_rules)\n",
    "            The triggered rule(s) of the input samples.\n",
    "        \n",
    "        '''\n",
    "        if self.n_rules==0:\n",
    "            raise ValueError(\"The algorithm can not find any path that \"\n",
    "                             \"satisfies constraints. Please consider \"\n",
    "                             \"relaxing one or more of the constraints.\")\n",
    "       \n",
    "        # Validate number of rules\n",
    "        if n_rules is None: n_rules = self.n_rules \n",
    "        Interval(\"n_rules\", n_rules, int, 0, self.n_rules, \"right\")\n",
    "    \n",
    "        X_rules = dict()\n",
    "        for n in range(1, n_rules+1):\n",
    "            alerts = rule_alert(X, self.rules[f\"Rule_{n}\"])\n",
    "            X_rules.update({f\"Rule_{n}\":alerts})\n",
    "            \n",
    "        return pd.DataFrame(X_rules)\n",
    "    \n",
    "    def fit_transform(self, X, y, n_rules=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model from the training set (X, y) and apply rules on X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, shape of (n_samples , n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target values (class labels) as integers.\n",
    "            \n",
    "        n_rules : int, default=None\n",
    "            Number of rules to be applied. If None, all rules are applied.\n",
    "       \n",
    "        Returns\n",
    "        -------\n",
    "        X_rules : pd.DataFrame, shape of (n_samples, n_rules)\n",
    "            The triggered rule(s) of the input samples.\n",
    "                  \n",
    "        '''\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, n_rules)\n",
    "    \n",
    "    def evaluate(self, X, y, n_rules=None, cumulative=False):\n",
    "        \n",
    "        '''\n",
    "        Apply selected rules on X and evaluate rule performance against y.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, shape of (n_samples , n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target values (class labels) as integers.\n",
    "        \n",
    "        n_rules : int, default=None\n",
    "            Number of rules to be applied e.g. if n_rules=2 then \"Rule_1\",\n",
    "            and \"Rule_2\" are applied. If None, all rules are applied.\n",
    "            \n",
    "        cumulative : bool, default=False\n",
    "            If True, all metrics are calculated in cumulative manner. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        info : pd.DataFrame, shape of (n_rules, n_metrics)\n",
    "        \n",
    "        '''\n",
    "        #  Validate cumulative\n",
    "        StrOptions([True, False], \"cumulative\", cumulative, bool)\n",
    "        \n",
    "        x = self.transform(X, n_rules).values.astype(int)\n",
    "        y = np.array(y).reshape(-1,1).copy()\n",
    "        \n",
    "        if cumulative:\n",
    "            n_targets = np.where((x==True) & (y==1),1,0)\n",
    "            n_targets = (np.cumsum(n_targets, axis=1)>0).sum(0)\n",
    "            n_samples = (np.cumsum(x, axis=1)>0).sum(0)\n",
    "        else:\n",
    "            n_targets = np.where((x==1) & (y==1),1,0).sum(0)\n",
    "            n_samples = x.sum(0)\n",
    "        \n",
    "        data = {\"rule\"      : np.arange(x.shape[1])+1,\n",
    "                \"n_targets\" : n_targets,\n",
    "                \"n_samples\" : n_samples,\n",
    "                \"precision\" : n_targets/n_samples,\n",
    "                \"recall\"    : n_targets/sum(y)}\n",
    "    \n",
    "        info = pd.DataFrame(data).set_index(\"rule\")\n",
    "        if cumulative: info.columns = [\"cum_targets\", \"cum_samples\", \n",
    "                                       \"precision\", \"recall\"]\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssoRule_base(X, y, start_with=None, metric=\"entropy\", \n",
    "                  operator=\"and\", min_lift=1, class_weights=None, \n",
    "                  rules=None, max_features=\"log2\", tol=1e-4):\n",
    "    \n",
    "    '''\n",
    "    Using the similar principle as \"Association rule\", but instead of \n",
    "    measuring on \"confidence\" or \"support\", it focuses on class \n",
    "    attribute i.e. \"1\" and finds the best RHS (a consequent rule) that\n",
    "    maximizes selected metric e.g. precision, or decile-lift given LHS\n",
    "    (antecedent rules).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : csc_matrix, of shape (n_samples, n_features)\n",
    "        Binary variables\n",
    "        \n",
    "    y : csc_matrix, of shape (n_samples, n_features)\n",
    "        Target values (binary)\n",
    "    \n",
    "    start_with : list of int, optional, default: None\n",
    "        List of starting feature indices. If None, the first variable \n",
    "        that has the highest score from specified `metric` will be \n",
    "        seleceted.\n",
    "        \n",
    "    metric : str, default=\"entropy\"\n",
    "        The function to evaluate the quality of rule (RHS). Supported \n",
    "        criteria are \"lift\" for the decile lift, \"recall\" for the \n",
    "        recall, \"precision\" for the precision, \"f1\" for the balanced \n",
    "        F-score, and \"entropy\" for the information gain. \n",
    "        \n",
    "    operator : {\"or\", \"and\"}, default=\"and\"\n",
    "        If \"or\", \"or\" operator is assigned as a relationship between \n",
    "        antecedent and consequent rules (n_operands > 0). If \"and\", \n",
    "        \"and\" operator is assigned (n_operands > 1).\n",
    "        \n",
    "    min_lift : float, default=1\n",
    "        The minimum per-decile lift required to continue. This is \n",
    "        relevant when metric is \"lift\".\n",
    "    \n",
    "    class_weights : \"balanced\" or dict, default=None\n",
    "        Weights associated with classes in the form {class_label: \n",
    "        weight}. If not given, all classes are supposed to have weight \n",
    "        one. The \"balanced\" mode uses the values of y to automatically \n",
    "        adjust weights inversely proportional to class frequencies in \n",
    "        the input data as n_samples / (n_classes * np.bincount(y)).\n",
    "        This is relevant when metric is \"entropy\".\n",
    "    \n",
    "    rules : dict, default=None\n",
    "        A dict with keys as column headers in `X`, and values as \n",
    "        interval e.g. {\"0\": (\"feature\", \">\", 10)}. If provided, `rule` \n",
    "        will be added to `asso_results_`. It contains a list of \n",
    "        subrules, which defines the specific intervals of a broader\n",
    "        rule.\n",
    "     \n",
    "    max_features : {\"sqrt\", \"log2\"}, int or float, default=\"log2\"\n",
    "        The number of features for stopping criteria.\n",
    "        - If int, then consider max_features features.\n",
    "        - If float, then max_features is a fraction and \n",
    "          round(max_features * n_features) features.\n",
    "        - If \"auto\", then max_features = log2(n_features).\n",
    "        - If \"sqrt\", then max_features = sqrt(n_features).\n",
    "        - If \"log2\", then max_features = log2(n_features)\n",
    "    \n",
    "    tol : float, default=1e-4\n",
    "        Tolerance for stopping criteria. This is relevant for all\n",
    "        metric except \"lift\".\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Results : collections.namedtuple\n",
    "        A dictionary subclass that contains fields as follows:\n",
    "        \n",
    "        Field        Description\n",
    "        -----        -----------\n",
    "        metric       Evaluating metric\n",
    "        operator     Relationship between rules\n",
    "        start_with   List of starting features\n",
    "        features     Selected features\n",
    "        cum_target   Cumulative number of targets\n",
    "        cum_sample   Cumulative number of samples\n",
    "        cum_lift     Cumulative lift\n",
    "        dec_lift     Decile lift\n",
    "        p_target     % target\n",
    "        p_sample     % sample\n",
    "        recall       Recall score\n",
    "        precision    Precision score\n",
    "        f1_score     F1 score\n",
    "        entropy      Entropy\n",
    "        rule         A list of subrules\n",
    "        \n",
    "        Note: all outputs are arranged according to `features`\n",
    "        \n",
    "    '''\n",
    "    if not isspmatrix_csc(X):\n",
    "        raise ValueError(f\"`X` must be Compressed Sparse Column \"\n",
    "                         f\"matrix (CSC), Got {type(X)} instead.\")\n",
    "        \n",
    "    if not isspmatrix_csc(y):\n",
    "        raise ValueError(f\"`y` must be Compressed Sparse Column \"\n",
    "                         f\"matrix (CSC), Got {type(y)} instead.\")\n",
    "    \n",
    "    if (X.shape!=y.shape):\n",
    "        raise ValueError(f\"Shape of `y` must be {X.shape}, \"\n",
    "                         f\"Got {y.shape} instead.\")\n",
    "        \n",
    "    if not isinstance(tol, numbers.Number) or (tol < 0):\n",
    "        raise ValueError(\"Tolerance for stopping criteria must \"\n",
    "                         \"be positive; got (tol=%r)\" % tol)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    values = {\"metric\"    : metric,\n",
    "              \"operator\"  : operator, \n",
    "              \"start_with\": start_with}\n",
    "    r_cum_lifts  , r_dec_lifts      = [], []\n",
    "    r_cum_targets, r_cum_samples    = [], [] \n",
    "    recall_scores, precision_scores = [], []\n",
    "    f1_scores    , r_entropies      = [], []\n",
    "        \n",
    "    # Compressed Sparse Column matrix (csc)\n",
    "    csc_true, csc_pred = y.copy(), X.copy()\n",
    "    n_targets = csc_true.sum(0).A.ravel()[0]\n",
    "    n_samples = csc_true.shape[0]\n",
    "    \n",
    "    # Keep index of rules ==> features\n",
    "    if rules is not None: features = np.r_[list(rules.keys())]\n",
    "    else: features = np.arange(csc_pred.shape[1])\n",
    "\n",
    "    # Maximum number of features.\n",
    "    max_features_ = get_max_features(max_features, csc_pred.shape[1])\n",
    "\n",
    "    # Remaining, and current indices \n",
    "    r_indices, c_indices = np.arange(csc_pred.shape[1]), []\n",
    "    \n",
    "    # Convert `start_with` to an array of column indices.\n",
    "    if start_with is None: start_with = np.array([], dtype=\"int32\")\n",
    "    else: start_with = r_indices[np.isin(r_indices, start_with)]\n",
    "        \n",
    "    # Convert `class_weights` to np.ndarray.\n",
    "    is_entropy = True if metric==\"entropy\" else False\n",
    "    class_weights = get_classweights(class_weights, y, is_entropy)\n",
    "  \n",
    "    while len(c_indices) < max_features_:\n",
    "\n",
    "        # Remaining features (sorted automatically)\n",
    "        r_indices = list(set(r_indices).difference(c_indices))\n",
    "\n",
    "        # Aantecedent and Consequent rules (n_samples,)\n",
    "        n_operands = 1 if operator==\"or\" else max(len(c_indices),1)\n",
    "        antecedent = (csc_pred[:,c_indices].sum(1)>=n_operands).astype(int)\n",
    "        consequent = csc_pred[:,r_indices]\n",
    "            \n",
    "        # New rules\n",
    "        if (len(c_indices)==0) | (operator==\"or\"):\n",
    "            new_rules = (consequent + antecedent) >= 1\n",
    "        else: new_rules = (consequent + antecedent) >= 2\n",
    "\n",
    "        # Lift components\n",
    "        (cum_targets, cum_samples, cum_lifts, \n",
    "         dec_lifts) = lift_base_csc(csc_true[:,r_indices], \n",
    "                                    new_rules.astype(int), \n",
    "                                    antecedent)\n",
    "        \n",
    "        # Confusion matrix, recall, precision, and f1\n",
    "        (tp, fp, fn, tn, new_recalls, \n",
    "         new_precisions, new_f1s) = cfm_base_csc(csc_true[:,r_indices], \n",
    "                                                 new_rules.astype(int))\n",
    "        \n",
    "        # Entropy\n",
    "        new_entropies = entropy_base_(tp, fp, fn, tn, class_weights)\n",
    "        \n",
    "        # Check metric crieria\n",
    "        if metric==\"lift\":\n",
    "            \n",
    "            pass_criteria = sum(dec_lifts>=min_lift) > 0\n",
    "            n = np.argmax(dec_lifts)\n",
    "            \n",
    "        elif metric==\"precision\":\n",
    "            \n",
    "            if len(precision_scores)==0: improve = new_precisions\n",
    "            else: improve = (new_precisions - precision_scores[-1])   \n",
    "            pass_criteria = sum(improve > tol) > 0\n",
    "            n = np.argmax(improve)\n",
    "            \n",
    "        elif metric==\"recall\":\n",
    "            \n",
    "            if len(recall_scores)==0: improve = new_recalls\n",
    "            else: improve = (new_recalls - recall_scores[-1])\n",
    "            pass_criteria = sum(improve > tol) > 0\n",
    "            n = np.argmax(improve)\n",
    "            \n",
    "        elif metric==\"f1\":\n",
    "            \n",
    "            if len(f1_scores)==0: improve = new_f1s\n",
    "            else: improve = (new_f1s - f1_scores[-1])\n",
    "            pass_criteria = sum(improve > tol) > 0\n",
    "            n = np.argmax(improve)\n",
    "            \n",
    "        elif metric==\"entropy\":\n",
    "        \n",
    "            if len(r_entropies)==0: \n",
    "                p = csc_true.mean()\n",
    "                p0 = (1-p)*np.log2(1-p) if p<1 else 0\n",
    "                p1 = p*np.log2(p) if p>0 else 0\n",
    "                ent = -sum(np.r_[p0, p1] * class_weights)\n",
    "                improve = ent - new_entropies\n",
    "            else: improve = (r_entropies[-1] - new_entropies)\n",
    "            pass_criteria = sum(improve > tol)>0\n",
    "            n = np.argmax(improve)\n",
    "      \n",
    "        else: pass\n",
    "        \n",
    "        # Need to pass metric criteria\n",
    "        if pass_criteria:\n",
    "            \n",
    "            # Select next `n` from `start_with`.\n",
    "            if len(start_with)>0: \n",
    "                n = np.argmax(r_indices==start_with[0])\n",
    "                start_with = start_with[1:]\n",
    "            \n",
    "            # Cumulative and Per-decile lifts.\n",
    "            r_cum_lifts += [cum_lifts[n]]\n",
    "            r_dec_lifts += [dec_lifts[n]]\n",
    "            \n",
    "            # Cumulative targets and samples.\n",
    "            r_cum_targets += [cum_targets[n]]\n",
    "            r_cum_samples += [cum_samples[n]]\n",
    "            \n",
    "            # Recall, Precisions,  F1s, and Entropy\n",
    "            recall_scores += [new_recalls[n]]\n",
    "            precision_scores += [new_precisions[n]]\n",
    "            f1_scores += [new_f1s[n]]\n",
    "            r_entropies += [new_entropies[n]]\n",
    "            \n",
    "            # Adding index to `c_indices`\n",
    "            c_indices = np.r_[c_indices, r_indices[n]].astype(int)\n",
    "            \n",
    "        else: break\n",
    "\n",
    "    # Returning results\n",
    "    if rules is None: rule = None\n",
    "    else: rule = [rules[i] for i in features[c_indices]]\n",
    "    values.update({\"features\"   : c_indices, \n",
    "                   \"cum_target\" : np.array(r_cum_targets), \n",
    "                   \"cum_sample\" : np.array(r_cum_samples), \n",
    "                   \"cum_lift\"   : np.array(r_cum_lifts), \n",
    "                   \"dec_lift\"   : np.array(r_dec_lifts), \n",
    "                   \"p_target\"   : np.array(r_cum_targets) / n_targets, \n",
    "                   \"p_sample\"   : np.array(r_cum_samples) / n_samples, \n",
    "                   \"recall\"     : np.array(recall_scores), \n",
    "                   \"precision\"  : np.array(precision_scores), \n",
    "                   \"f1_score\"   : np.array(f1_scores), \n",
    "                   \"entropy\"    : np.array(r_entropies), \n",
    "                   \"rule\"       : rule})\n",
    "    return namedtuple(\"Results\", values.keys())(**values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_base_csc(csc_true, csc_pred, csc_prev):\n",
    "    \n",
    "    '''\n",
    "    Cumulative and decile lifts (Compressed Sparse Column matrix)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csc_true : csc_matrix, of shape (n_samples, n_features)\n",
    "    csc_pred : csc_matrix, of shape (n_samples, n_features)\n",
    "    csc_prev : csc_matrix, of shape (n_samples, 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cum_targets : cumulative number of targets\n",
    "    cum_samples : cumulative number of samples\n",
    "    cum_lifts   : cumulative lifts\n",
    "    dec_lifts   : cumulative decile lifts\n",
    "    \n",
    "    '''\n",
    "    # Number of targets and samples (float)\n",
    "    n_targets = sum(csc_true[:,[0]].A.ravel())\n",
    "    n_samples = csc_true.shape[0]\n",
    "\n",
    "    # Cumulative number of targets and samples by varibale\n",
    "    # of shape (n_features,)\n",
    "    cum_targets = ((csc_true + csc_pred)==2).sum(0).A.ravel()\n",
    "    cum_samples = csc_pred.sum(axis=0).A.ravel()\n",
    "\n",
    "    # Cumulative number of existing targets,and samples.\n",
    "    ext_targets = ((csc_prev + csc_true[:,[0]])==2).sum(0).A.ravel()[0]\n",
    "    ext_samples = csc_prev.sum(0).A.ravel()[0]\n",
    "\n",
    "    # Calculate change of targets and samples (n_features,)\n",
    "    delta_t = (cum_targets - ext_targets) / n_targets \n",
    "    delta_s = (cum_samples - ext_samples) / n_samples \n",
    "\n",
    "    # Cumulative, and Per-decile lifts\n",
    "    denom = np.fmax(cum_samples, 0.5) / n_samples\n",
    "    cum_lifts = (cum_targets/n_targets) / denom\n",
    "    dec_lifts = delta_t / np.where(delta_s==0, 1, delta_s)\n",
    "    \n",
    "    return cum_targets, cum_samples, cum_lifts, dec_lifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfm_base_csc(csc_true, csc_pred):\n",
    "    \n",
    "    '''\n",
    "    Confusion matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csc_true : csc_matrix, of shape (n_samples, n_features)\n",
    "    csc_pred : csc_matrix, of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tp, fp, fn, tn, recall, precision, f1\n",
    "    \n",
    "    '''\n",
    "    # Confusion matrix\n",
    "    n_samples = csc_pred.shape[0]\n",
    "    tp = ((csc_pred + csc_true)== 2).sum(0).A.ravel()\n",
    "    fp = ((csc_true - csc_pred)==-1).sum(0).A.ravel()\n",
    "    fn = ((csc_pred - csc_true)==-1).sum(0).A.ravel()\n",
    "    tn = n_samples - (tp + fp + fn)\n",
    "    \n",
    "    recall = tp / np.fmax(tp + fn, 1)\n",
    "    precision = tp / np.fmax(tp + fp, 1)\n",
    "    denom = np.fmax(recall + precision, 1)\n",
    "    f1 = (2 * recall * precision) / denom\n",
    "    return tp, fp, fn, tn, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_base_(n11, n10, n01, n00, class_weights):\n",
    "    \n",
    "    '''\n",
    "    Entropy (Information Gain).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n11 : np.ndarray, of shape (n_features,)\n",
    "    n10 : np.ndarray, of shape (n_features,)\n",
    "    n01 : np.ndarray, of shape (n_features,)\n",
    "    n00 : np.ndarray, of shape (n_features,)\n",
    "    class_weights : np.ndarray, of shape (n_classes,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Entropies : np.ndarray, of shape (n_features,)\n",
    "    \n",
    "    '''\n",
    "    # Weights\n",
    "    N = n11 + n10 + n01 + n00\n",
    "    w1 = ((n11 + n10) / N).reshape(-1,1)\n",
    "    w0 = ((n01 + n00) / N).reshape(-1,1)\n",
    "    \n",
    "    # Probabilities\n",
    "    p11 = n11 / np.fmax(n11 + n10, 1)\n",
    "    p10 = n10 / np.fmax(n11 + n10, 1)\n",
    "    p01 = n01 / np.fmax(n01 + n00, 1)\n",
    "    p00 = n00 / np.fmax(n01 + n00, 1)\n",
    "\n",
    "    ENT = lambda p: p*np.log2(np.where(p==0,1,p))\n",
    "    entropies = ((-w1 * np.vstack([ENT(p10),ENT(p11)]).T * \n",
    "                  class_weights).sum(1) +\n",
    "                 (-w0 * np.vstack([ENT(p00),ENT(p01)]).T * \n",
    "                  class_weights).sum(1))\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_features(max_features, n_features):\n",
    "    \n",
    "    '''Private function: find max number of features'''\n",
    "    if isinstance(max_features, str):     \n",
    "        if max_features == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        elif max_features == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        else: raise ValueError(\"Invalid value for max_features. \"\n",
    "                               \"Allowed string values are 'sqrt'\"\n",
    "                               \" or 'log2'.\")\n",
    "    elif isinstance(max_features, int):\n",
    "        return min(max(max_features,1), n_features)\n",
    "    elif isinstance(max_features, float):\n",
    "        p = min(1, max_features)\n",
    "        return max(1, int(p * n_features))\n",
    "    else: return n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classweights(class_weights, y, is_entropy):\n",
    "    \n",
    "    '''\n",
    "    `class_weights`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    class_weights : str or dict {class_label: weight}\n",
    "    y : np.ndarray, of shape (n_samples,)\n",
    "    is_entropy : bool\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    class_weights : np.ndarray of shape (n_classes,)\n",
    "    \n",
    "    '''\n",
    "    n_classes = len(np.unique(y))\n",
    "    if (class_weights==\"balanced\") & is_entropy:\n",
    "        return len(y)/(n_classes*np.bincount(y)) \n",
    "    elif isinstance(class_weights, dict) & is_entropy:\n",
    "        return np.array([class_wights[c] for c in np.unique(y)])\n",
    "    else: return np.ones(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssoRuleMining:\n",
    "    \n",
    "    '''\n",
    "    Using the similar principle as \"Association rule\", but instead of \n",
    "    measuring on \"confidence\" or \"support\", it focuses on class \n",
    "    attribute i.e. \"1\" and finds the best RHS (a consequent rule) that\n",
    "    maximizes selected metric e.g. precision, or decile-lift given LHS\n",
    "    (antecedent rules).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    metric : str, default=\"entropy\"\n",
    "        The function to evaluate the quality of rule (RHS). Supported \n",
    "        criteria are \"lift\" for the decile lift, \"recall\" for the \n",
    "        recall, \"precision\" for the precision, \"f1\" for the balanced \n",
    "        F-score, and \"entropy\" for the information gain. \n",
    "    \n",
    "    operator : {\"or\", \"and\"}, default=\"or\"\n",
    "        If \"or\", \"or\" operator is assigned as a relationship between \n",
    "        antecedent and consequent rules (n_operands > 0). If \"and\", \n",
    "        \"and\" operator is assigned (n_operands > 1).\n",
    "       \n",
    "    min_lift : float, default=1\n",
    "        The minimum per-decile lift required to continue. This is \n",
    "        relevant when metric is \"lift\".\n",
    "    \n",
    "    class_weights : \"balanced\" or dict, default=None\n",
    "        Weights associated with classes in the form {class_label: \n",
    "        weight}. If not given, all classes are supposed to have \n",
    "        weight one. The \"balanced\" mode uses the values of y to \n",
    "        automatically adjust weights inversely proportional to class \n",
    "        frequencies in the input data as n_samples / (n_classes * \n",
    "        np.bincount(y)). This is relevant when metric is \"entropy\".\n",
    "        \n",
    "    max_features : {\"sqrt\", \"log2\"}, int or float, default=\"log2\"\n",
    "        The number of features for stopping criteria.\n",
    "        - If int, then consider max_features features.\n",
    "        - If float, then max_features is a fraction and \n",
    "          round(max_features * n_features) features.\n",
    "        - If \"auto\", then max_features = log2(n_features).\n",
    "        - If \"sqrt\", then max_features = sqrt(n_features).\n",
    "        - If \"log2\", then max_features = log2(n_features)\n",
    "    \n",
    "    tol : float, default=1e-4\n",
    "        Tolerance for stopping criteria. This is relevant for all\n",
    "        metric except \"lift\".\n",
    "    \n",
    "    n_jobs : int, default=None\n",
    "        Number of CPU cores used when parallelizing over combination\n",
    "        of subrules. None means 1 and -1 means using all processors.\n",
    "    \n",
    "    n_batches : int, default=2\n",
    "        Number of batches (iterations) to process `n_features` \n",
    "        combinations.\n",
    "        \n",
    "    min_support : int or float, default=1e-4\n",
    "        The minimum support determines how often the rule is \n",
    "        applicable to a given `y` or targets, and is used to eliminate \n",
    "        features using the support-based pruning strategy.\n",
    "        - If int, then consider min_support targets.\n",
    "        - If float, then min_support is a fraction and \n",
    "          round(min_support * sum(y)) targets.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    asso_results_ : dict of collections.namedtuple\n",
    "        A dict with keys as antecedent variables (`start_with` \n",
    "        excluded), and namedtuple (\"Results\") as values, whose fields\n",
    "        are as follows:\n",
    "    \n",
    "        Field        Description\n",
    "        -----        -----------\n",
    "        metric       Evaluating metric\n",
    "        operator     Relationship between rules\n",
    "        start_with   List of starting features\n",
    "        features     Selected features\n",
    "        cum_target   Cumulative number of targets\n",
    "        cum_sample   Cumulative number of samples\n",
    "        cum_lift     Cumulative lift\n",
    "        dec_lift     Decile lift\n",
    "        p_target     % target\n",
    "        p_sample     % sample\n",
    "        recall       Recall score\n",
    "        precision    Precision score\n",
    "        f1_score     F1 score\n",
    "        entropy      Entropy\n",
    "        rule         A list of subrules\n",
    "        \n",
    "        Note: all outputs are arranged according to `features`\n",
    "        \n",
    "    info : dict of numpy (masked) ndarrays\n",
    "        A summary table that comes in a form of dict with keys as \n",
    "        column headers. It can be imported into a pandas DataFrame, \n",
    "        whose fields are as follows:\n",
    "\n",
    "        Field       Description\n",
    "        -----       -----------\n",
    "        start_with  List of starting features\n",
    "        variable    First consequent rule (RHS)\n",
    "        n_features  Number of features\n",
    "        p_target    % target\n",
    "        p_sample    % sample\n",
    "        recall      Recall score\n",
    "        precision   Precision score\n",
    "        f1_score    F1 score\n",
    "        entropy     Entropy\n",
    "        \n",
    "        Note: [1] row with identical results, will be dropped, and \n",
    "              [2] select one, whose \"n_features\" is the smallest.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, metric=\"entropy\", operator=\"or\", min_lift=1, \n",
    "                 class_weights=None, max_features=\"log2\", tol=1e-4, \n",
    "                 n_jobs=None, n_batches=2, min_support=1e-4):\n",
    "        \n",
    "        # Keyword arguments for `AssoRule_base`.\n",
    "        self.kwargs = {\"metric\"        : metric, \n",
    "                       \"operator\"      : operator, \n",
    "                       \"min_lift\"      : min_lift, \n",
    "                       \"class_weights\" : class_weights, \n",
    "                       \"max_features\"  : max_features, \n",
    "                       \"tol\"           : tol}\n",
    "        \n",
    "        # Number of processors required\n",
    "        max_CPU = multiprocessing.cpu_count()\n",
    "        if isinstance(n_jobs, int):\n",
    "            if n_jobs == -1: self.n_jobs = max_CPU \n",
    "            else: self.n_jobs = min(max(1,n_jobs), max_CPU)\n",
    "        else: self.n_jobs = 1\n",
    "        \n",
    "        # Number of batches\n",
    "        self.n_batches = (max(n_batches, 1) if \n",
    "                          isinstance(n_batches, int) else 1)\n",
    "        \n",
    "        # Tolerance\n",
    "        if not isinstance(tol, numbers.Number) or (tol < 0):\n",
    "            raise ValueError(\"Tolerance for stopping criteria must \"\n",
    "                             \"be positive; got (tol=%r)\" % tol)\n",
    "        \n",
    "        # Minimum support\n",
    "        if not isinstance(min_support, (int,float)):\n",
    "             raise ValueError(f\"Invalid dtype for min_support. \"\n",
    "                              f\"Allowed dtype values are int or float.\"\n",
    "                              f\" Got {type(min_support)} instead.\")    \n",
    "        elif min_support < 0:\n",
    "            raise ValueError(f\"`min_support` must be positive, Got \"\n",
    "                             f\"{min_support}.\")\n",
    "        elif isinstance(min_support, float) & (min_support>=1):\n",
    "            raise ValueError(f\"If float, `min_support` must be less \"\n",
    "                             f\"than 1, Got {min_support}.\")\n",
    "        else: self.min_support = min_support\n",
    "            \n",
    "    def __Pruning__(self, X, y, start_with):\n",
    "        \n",
    "        '''\n",
    "        Support-based pruning\n",
    "        \n",
    "        Parameters\n",
    "        ----------     \n",
    "        X : pd.DataFrame, shape of (n_samples, n_features)\n",
    "        y : array-like of shape (n_samples,)\n",
    "        start_with : list of columns in `X`\n",
    "        self.min_support : Minimum support (int, float)\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        self.start_with : List of features to be started off with\n",
    "        self.features   : Remaining features\n",
    "        self.n_features : Number of remaining features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        csc_pred : csc_matrix, of shape (n_samples, self.n_features)\n",
    "        csc_true : csc_matrix, of shape (n_samples, self.n_features)\n",
    "        \n",
    "        '''\n",
    "        # Compressed Sparse Column matrix (csc) ==> X.shape\n",
    "        csc_true = csc(np.hstack([y.reshape(-1,1)]*X.shape[1]))\n",
    "        csc_pred = csc(X.values.astype(int)).copy()\n",
    "        features = np.array(list(X)) # <-- Initial set of features\n",
    "        n_targets= sum(y)\n",
    "        \n",
    "        # Convert minimum support to integer (count)\n",
    "        if isinstance(self.min_support, float):\n",
    "            min_support = int(min(1, self.min_support)*n_targets)\n",
    "        else: min_support = self.min_support\n",
    "        self.min_support_ = max(min(n_targets, min_support),0)\n",
    "    \n",
    "        # Number of actual supports\n",
    "        n_supports = ((csc_pred + csc_true)==2).sum(0).A.ravel()\n",
    "        self.start_with = [] if start_with is None else start_with\n",
    "        \n",
    "        # Keep indices\n",
    "        keep  = n_supports >= self.min_support_\n",
    "        keep |= np.isin(features, self.start_with)\n",
    "        \n",
    "        # Attributes\n",
    "        self.features = features[keep]\n",
    "        self.n_features = len(self.features)\n",
    "        return csc_pred[:, keep], csc_true[:, keep]\n",
    "    \n",
    "    def __CreateBatch__(self, feature_indices):\n",
    "        \n",
    "        '''\n",
    "        Create batches\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_indices : List of feature indices \n",
    "        self.n_feature  : number of features\n",
    "        self.n_bathes   : number of batches\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        batches, n_batches\n",
    "        \n",
    "        '''\n",
    "        batch_size = int(np.ceil(self.n_features / self.n_batches))\n",
    "        sections = np.arange(0, self.n_features, batch_size)\n",
    "        subarray = np.split(feature_indices, sections)\n",
    "        batches  = [b for b in subarray if len(b) > 0]\n",
    "        return batches, len(batches)\n",
    "    \n",
    "    def __ChangeKeys__(self, dok, pairs):\n",
    "        \n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        dok : Dictionary of keys \n",
    "        pairs : List of tuples i.e. [(new_key, old_key)]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        new_dict : Dictionary with new keys\n",
    "        \n",
    "        '''\n",
    "        new_dict = dict()\n",
    "        for new_key, old_key in pairs:\n",
    "            new_dict[new_key] = dok[old_key]\n",
    "        return new_dict\n",
    "        \n",
    "    def fit(self, X, y, start_with=None, rules=None):\n",
    "        \n",
    "        '''\n",
    "        Fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, shape of (n_samples, n_features)\n",
    "            Binary variables\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values (binary)\n",
    " \n",
    "        start_with : list of columns, optional, default: None\n",
    "            List of starting features in `X`. If None, the first variable \n",
    "            that has the highest score from specified `metric` will be \n",
    "            seleceted.\n",
    "        \n",
    "        rules : dict, default=None\n",
    "            A dict with keys as column headers in `X`, and values as \n",
    "            interval e.g. {\"0\": (\"feature\", \">\", 10)}. If provided, `rule` \n",
    "            will be added to `asso_results_`. It contains a list of \n",
    "            subrules, which defines the specific intervals of a broader\n",
    "            rule.\n",
    " \n",
    "        '''\n",
    "        # Initialize widgets\n",
    "        w1 = widgets.HTMLMath(value='Calculating . . .')\n",
    "        w2 = widgets.HTMLMath(value='')\n",
    "        w = widgets.HBox([w1, w2])\n",
    "        display(w); time.sleep(1)\n",
    "        \n",
    "        # Initialize parameters.\n",
    "        start = time.time()\n",
    "        self.asso_results_ = dict()\n",
    "\n",
    "        # Support-based pruning\n",
    "        csc_pred, csc_true = self.__Pruning__(X, y, start_with)\n",
    "        args = (csc_pred, csc_true)\n",
    "        \n",
    "        # Create indices for all features and `start_with`.\n",
    "        f_indices = np.arange(self.n_features)\n",
    "        s_indices = f_indices[np.isin(self.features, \n",
    "                                      self.start_with)].tolist()\n",
    "        pairs = [p for p in zip(f_indices, self.features)]\n",
    "        \n",
    "        # Create batches for parellel processing\n",
    "        batches, n_batches = self.__CreateBatch__(f_indices)\n",
    "        \n",
    "        # Change current keys of rules to match indices.\n",
    "        if rules is None: adj_rules = None\n",
    "        else: adj_rules = self.__ChangeKeys__(rules, pairs)\n",
    "        \n",
    "        # Set partial functions.\n",
    "        kwds = {**self.kwargs, **dict(rules=adj_rules)}\n",
    "        assorule = partial(AssoRule_base, **kwds)\n",
    "        asso_job = Parallel(n_jobs=self.n_jobs)\n",
    "        \n",
    "        # Run batch\n",
    "        t = 'Calculating . . . Batch : ({:,d}/{:,d})'\n",
    "        w1.value = t.format(0, n_batches)\n",
    "        for n,batch in enumerate(batches, 1):\n",
    "            \n",
    "            results = list()\n",
    "            for var in batch:\n",
    "                if var not in self.start_with:\n",
    "                    kwargs = {\"start_with\":self.start_with + [var]}\n",
    "                    results += [delayed(assorule)(*args, **kwargs)]\n",
    "            results = asso_job(results)\n",
    "\n",
    "            for var,res in zip(batch, results):    \n",
    "                # Change indices back to original columns in `X`\n",
    "                dok = res._asdict()\n",
    "                dok.update({\"start_with\": self.features[dok[\"start_with\"]], \n",
    "                            \"features\"  : self.features[dok[\"features\"]]})\n",
    "                self.asso_results_[self.features[var]] = \\\n",
    "                namedtuple(\"Results\", dok.keys())(**dok)\n",
    "            w1.value = t.format(n, n_batches)\n",
    "        \n",
    "        w1.value = 'Number of features : %d' % self.n_features\n",
    "        r_time = time.gmtime(time.time() - start)\n",
    "        r_time = time.strftime(\"%H:%M:%S\", r_time)\n",
    "        w2.value = ', Total running time: {}'.format(r_time)\n",
    "        \n",
    "        # Create attribute `info`.\n",
    "        self.__CreateInfo__()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def __CreateInfo__(self):\n",
    "        \n",
    "        '''\n",
    "        Summary of all combinations.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        info : dict of numpy (masked) ndarrays\n",
    "            A dict with keys as column headers. It can be imported into a \n",
    "            pandas DataFrame, whose fields are as follows:\n",
    "\n",
    "            Field       Description\n",
    "            -----       -----------\n",
    "            start_with  List of starting features\n",
    "            variable    First consequent rule (RHS)\n",
    "            n_features  Number of features\n",
    "            p_targets   % targets\n",
    "            p_samples   % samples\n",
    "            recalls     Recall scores\n",
    "            precisions  Precision scores\n",
    "            f1_scores   F1 scores\n",
    "            entropies   Entropies\n",
    "            \n",
    "            Note: [1] row with identical results, will be dropped, and \n",
    "                  [2] select one, whose \"n_features\" is the smallest.\n",
    "                  \n",
    "        '''\n",
    "        data = []\n",
    "        if len(self.start_with)==0: start = None\n",
    "        else: start = \", \".join(self.start_with) \n",
    "        for var in self.asso_results_.keys():\n",
    "            a = self.asso_results_[var]\n",
    "            data += [{\"start_with\" : start, \n",
    "                      \"variable\"   : var,\n",
    "                      \"n_features\" : len(a.features), \n",
    "                      \"p_target\"   : a.p_target[-1], \n",
    "                      \"p_sample\"   : a.p_sample[-1], \n",
    "                      \"f1_score\"   : a.f1_score[-1],\n",
    "                      \"recall\"     : a.recall[-1], \n",
    "                      \"precision\"  : a.precision[-1],\n",
    "                      \"entropy\"    : a.entropy[-1]}]\n",
    " \n",
    "        # Drop entries with identical results and select\n",
    "        # one, whose \"n_features\" is the smallest.\n",
    "        subset = [\"p_target\", \"p_sample\", \"f1_score\", \n",
    "                  \"recall\", \"precision\", \"entropy\"]\n",
    "        data = pd.DataFrame(data)\\\n",
    "        .sort_values(by=[\"n_features\"], ascending=[True])\n",
    "        data.drop_duplicates(subset=subset, keep=\"first\", \n",
    "                             ignore_index=True,  inplace=True)\n",
    "        self.info = pd.DataFrame(data).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dtype(X, max_category=10):\n",
    "    \n",
    "    '''\n",
    "    This function converts columns to possible dtypes which are \n",
    "    \"float32\", \"int32\" (boolean), \"category\", and \"object\". However, \n",
    "    it ignores columns, whose dtype is either np.datetime64 or \n",
    "    np.timedelta64.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame, of shape (n_samples, n_features)\n",
    "        Input array.\n",
    "    \n",
    "    max_category : int, default=10\n",
    "        If number of unique elements from column with \"object\" dtype, \n",
    "        is less than or equal to max_category, its dtype will be \n",
    "        converted to \"category\". max_category must be greater than or \n",
    "        equal to 2.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_converted : pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    # Select columns, whose dtype is neither datetimes, nor timedeltas.\n",
    "    exclude = [np.datetime64, np.timedelta64] \n",
    "    columns = list(X.select_dtypes(exclude=exclude))\n",
    "    \n",
    "    if isinstance(max_category, int): \n",
    "        max_category = max(2, max_category)\n",
    "    else: max_category = 10\n",
    "    \n",
    "    # Replace pd.isnull() with np.nan\n",
    "    X_converted = X.copy()\n",
    "    X_converted.iloc[:,:] = np.where(X.isnull(), np.nan, X)\n",
    "    \n",
    "    for var in columns:\n",
    "        x = X_converted[var].copy()\n",
    "        try:\n",
    "            float32 = x.astype(\"float32\")\n",
    "            if np.isnan(float32).sum()==0:\n",
    "                int32 = x.astype(\"int32\")\n",
    "                if (int32-float32).sum()==0: X_converted[var] = int32\n",
    "                else: X_converted[var] = float32\n",
    "            else: X_converted[var] = float32 \n",
    "        except:\n",
    "            objtype = x.astype(\"object\")\n",
    "            n_unq = len(objtype.unique())\n",
    "            if n_unq<=max_category:\n",
    "                X_converted[var] = x.astype(str).astype(\"category\") \n",
    "            else: X_converted[var] = objtype\n",
    "    return X_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_DataFrame(X) -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    ** Private Function **\n",
    "    If `X` is not `pd.DataFrame`, column(s) will be automatically \n",
    "    created with \"Unnamed\" format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    if not (hasattr(X,'shape') or hasattr(X,'__array__')):\n",
    "        raise TypeError(f'Data must be array-like. '\n",
    "                        f'Got {type(X)} instead.')\n",
    "    elif isinstance(X, pd.Series):\n",
    "        return pd.DataFrame(X)\n",
    "    elif not isinstance(X, pd.DataFrame):\n",
    "        try:\n",
    "            z = int(np.log(X.shape[1])/np.log(10)+1)\n",
    "            columns = ['Unnamed_{}'.format(str(n).zfill(z)) \n",
    "                       for n in range(1,X.shape[1]+1)]\n",
    "        except: columns = ['Unnamed']\n",
    "        return pd.DataFrame(X, columns=columns)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discretize:\n",
    "    \n",
    "    '''\n",
    "    Discretization is the process in which continuous variables can \n",
    "    be transformed into a discrete form through use of intervals. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_cutoffs : int, default=10\n",
    "        Number of cutoffs. Number of actual cutoff could be less than \n",
    "        `n_cutoffs` due to rounding of decimals and uniqueness of \n",
    "        values. This is relevant when criterion is either \n",
    "        \"equal-width\" or \"equal-sample\".\n",
    "        \n",
    "    criterion : str, default=\"equal-width\"\n",
    "        The function to calculate edges of the bins.\n",
    "        - If \"equal-width\", it is the equal-width binning.\n",
    "        - If \"equal-sample\", it is the equal-sample binning.\n",
    "        - If \"tree\", it uses sklearn tree base-learner i.e.\n",
    "          DecisionTreeRegressor or DecisionTreeClassifier (this is\n",
    "          relevant when y is provided) to determine bin edges.\n",
    "          \n",
    "    decimal : int, default=None\n",
    "        Rounding decimals of bin-edges. If None, rounding is ignored.\n",
    "    \n",
    "    auto_astype : bool, default=False\n",
    "        If True, it converts columns to possible dtypes which are \n",
    "        \"float32\", \"int32\" (boolean), \"category\", and \"object\" before\n",
    "        binning is carried out. However, it ignores columns, whose \n",
    "        dtype is either np.datetime64 or np.timedelta64.\n",
    "    \n",
    "    max_category : int, default=10\n",
    "        If number of unique elements from column with \"object\" dtype, \n",
    "        is less than or equal to max_category, its dtype will be \n",
    "        converted to \"category\". max_category must be greater than or \n",
    "        equal to 2. This is revelvant when auto_astype is True.\n",
    "        \n",
    "    min_samples : int or float, default=0.05\n",
    "        The minimum number of samples required to be at a leaf node. \n",
    "        - If int, then consider min_samples as the minimum number.\n",
    "        - If float, then min_samples is a fraction and ceil\n",
    "          (min_samples * n_samples) are the minimum number of samples \n",
    "          for each node.\n",
    "          \n",
    "    random_state : int, default=0\n",
    "        Controls the randomness of generating y with a uniform \n",
    "        distribution. This is relevant with y is not provided.\n",
    "        \n",
    "    '''\n",
    "    num_dtypes = [\"float32\", \"float64\", \"int32\", \"int64\"]\n",
    "    \n",
    "    def __init__(self, n_cutoffs=10, criterion=\"equal-width\", \n",
    "                 decimal=4, auto_astype=False, max_category=10, \n",
    "                 min_samples=0.05, random_state=0):\n",
    "        \n",
    "        self.__PositiveInt__(\"n_cutoffs\", n_cutoffs)\n",
    "        self.__PositiveInt__(\"decimal\", decimal)\n",
    "        self.__PositiveInt__(\"max_category\", max_category) \n",
    "        \n",
    "        if criterion not in [\"equal-width\", \"equal-sample\", \"tree\"]:\n",
    "            raise ValueError('criterion must be either \"equal-width\", '\n",
    "                             '\"equal-sample\" or \"tree\", got %s' % \n",
    "                             criterion)\n",
    "        \n",
    "        self.n_cutoffs = n_cutoffs\n",
    "        self.criterion = criterion\n",
    "        self.decimal = decimal\n",
    "        self.auto_astype = auto_astype\n",
    "        self.max_category = max_category\n",
    "        self.min_samples = min_samples\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __PositiveInt__(self, name, value, amin=0, amax=100):\n",
    "        \n",
    "        err_msg = \"%s must be positive integer or in \"\\\n",
    "        \"(%s, %s], got %s\" % (name, amin, amax, value)\n",
    "        if isinstance(value, int):\n",
    "            if not amin < value <= amax: \n",
    "                raise ValueError(err_msg)\n",
    "        else: raise ValueError(err_msg)\n",
    "    \n",
    "    def transform(self, X, y=None, start_index=0):\n",
    "        \n",
    "        '''\n",
    "        Apply discretization and/or data type conversion on X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame, of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        \n",
    "        y : array-like of shape (n_samples,), default=None\n",
    "            The target values (class labels) as integers.\n",
    "        \n",
    "        start_index : int, default=0\n",
    "            Starting index of columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_discretized : pd.DataFrame of (n_samples, n_discretized)\n",
    "            Discretized variables in X.\n",
    "\n",
    "        rules : dict\n",
    "            A dict with keys as column headers in `X_discretized`, \n",
    "            and values as interval e.g. (\"feature\", \">\", 10)\n",
    "\n",
    "        '''\n",
    "        # Check X \n",
    "        X = to_DataFrame(X).copy()\n",
    "        if self.auto_astype: \n",
    "            X = define_dtype(X, self.max_category)\n",
    "    \n",
    "        # Initialize parameters\n",
    "        features, n_samples = list(X), len(X)\n",
    "        arr, rules, index = [],  {}, int(start_index)-1\n",
    "        \n",
    "        for var in features:\n",
    "            x = X[var].values\n",
    "      \n",
    "            if str(x.dtype) in self.num_dtypes:\n",
    "                \n",
    "                # According to binning method (equal-width or equal-sample),\n",
    "                # this function generates 1-dimensional and monotonic array \n",
    "                # of bins.\n",
    "                if self.criterion == \"equal-width\":\n",
    "                    bins = np.linspace(np.nanmin(x), np.nanmax(x), \n",
    "                                       self.n_cutoffs+2)\n",
    "                    bins = np.unique(np.round(bins, self.decimal))[1:-1]\n",
    "                    \n",
    "                elif self.criterion == \"equal-sample\":\n",
    "                    q = np.linspace(0, 100, self.n_cutoffs+2)\n",
    "                    bins = np.nanpercentile(x, q)\n",
    "                    bins = np.unique(np.round(bins, self.decimal))[1:-1]\n",
    "                    \n",
    "                elif self.criterion == \"tree\":\n",
    "                    args = (np.round(x, self.decimal), y, \n",
    "                            self.min_samples, self.random_state)\n",
    "                    bins = treebased_binning(*args)[1:-1]\n",
    "                \n",
    "                if len(bins)>0:\n",
    "                    \n",
    "                    # Determine difference between x and all edges\n",
    "                    x_diff = np.full((n_samples, len(bins)),\n",
    "                                     x.reshape(-1,1))-bins\n",
    "                    \n",
    "                    # Create varialbes\n",
    "                    for attr, sign in [(\"less_equal\",\"<=\"), (\"greater\",\">\")]:\n",
    "                        arr += [getattr(np, attr)(x_diff, 0)]\n",
    "                        rules.update(dict((n,(var,sign,v)) for n,v in \n",
    "                                          enumerate(bins, index + 1)))\n",
    "                        index += len(bins)\n",
    "                        \n",
    "            elif str(x.dtype) == \"category\":\n",
    "                categories = np.unique(x)\n",
    "                arr += [np.hstack([x==c for c in categories])]\n",
    "                rules.update(dict((n,(var, \"==\", v)) for n,v in \n",
    "                                  enumerate(categories, index + 1)))\n",
    "                index += len(categories)\n",
    "\n",
    "        X_discretized = pd.DataFrame(np.hstack(arr).astype(int))\n",
    "        X_discretized.columns = range(start_index, index+1)\n",
    "        return X_discretized, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_alert(X, rule_set):\n",
    "    \n",
    "    '''\n",
    "    It returns True or False given rule_set \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame, of shape (n_samples, n_features)\n",
    "        Input data.\n",
    "        \n",
    "    rule_set : collections.namedtuple\n",
    "        A tuple subclass named \"Rule\" (typename).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    alerts : array of boolean\n",
    "    \n",
    "    '''\n",
    "    func = {\"==\": np.equal, \n",
    "            \"!=\": np.not_equal,\n",
    "            \"<\" : np.less, \n",
    "            \">=\": np.greater_equal, \n",
    "            \"<=\": np.less_equal,\n",
    "            \">\" : np.greater}\n",
    "    \n",
    "    try: # no sub-rule\n",
    "        alerts = [func[sign](np.array(X[var]), value)\n",
    "                  for var,sign,value in rule_set.rule]\n",
    "    except: # sub-rule (recursive)\n",
    "        alerts = [rule_alert(X, rule) for rule in rule_set.rule]\n",
    "        \n",
    "    alerts = np.vstack(alerts).T.sum(1)\n",
    "    if rule_set.operator==\"or\": return alerts > 0\n",
    "    else: return alerts == len(rule_set.rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RuleToFeature(X, asso_results_, which_rules=None):\n",
    "    \n",
    "    '''\n",
    "    Convert rules into features array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame, of shape (n_samples, n_features)\n",
    "        Input data.\n",
    "    \n",
    "    asso_results_ : dict of collections.namedtuple\n",
    "        An attribute from fitted `AssoRuleMining`. The conversion\n",
    "        requires that every key must contain a list of subrules i.e.\n",
    "        a field, namely \"rule\" must not be None.\n",
    "    \n",
    "    which_rules : list of keys, default=None\n",
    "        A list of selectd keys in `asso_results_`. If None, all keys\n",
    "        will be converted.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_converted : pd.DataFrame of shape (n_samples, n_rules)\n",
    "        A converted X.\n",
    "    \n",
    "    rules : dict\n",
    "        A dict with keys as column headers (indices) in `X_converted`, \n",
    "        and values as tuple subclass named \"Rule\" e.g. \n",
    "        Rule(rule=[('feature', '==', '0')]).\n",
    "    \n",
    "    '''\n",
    "    # Initialize parameters\n",
    "    X_converted, rules = [], dict()\n",
    "    Rule = namedtuple(\"Rule\",[\"rule\", \"operator\"])\n",
    "    \n",
    "    # Determine number of rules to be converted.\n",
    "    keys = np.r_[list(asso_results_.keys())]\n",
    "    which_rules = (keys[np.isin(keys, which_rules)] \n",
    "                   if which_rules is not None else keys)\n",
    "\n",
    "    for key in which_rules:\n",
    "        # Store an array of converted rule and rule details.\n",
    "        result = asso_results_[key]\n",
    "        X_converted += [rule_alert(X.copy(), result).reshape(-1,1)]\n",
    "        rules[key] = Rule(*(result.rule, result.operator))\n",
    "        \n",
    "    X_converted = pd.DataFrame(np.hstack(X_converted),\n",
    "                               columns=which_rules)        \n",
    "    return X_converted, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(y_true, y_pred, decimal=1):\n",
    "    \n",
    "    '''\n",
    "    Prints the summary table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d array-like, or label indicator array\n",
    "        Ground truth (correct) target values.\n",
    "\n",
    "    y_pred : 1d array-like, or label indicator array\n",
    "        Estimated targets.\n",
    "        \n",
    "    decimal : int, default=1\n",
    "        Decimal place for %.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> print_stats(y_true, y_pred)\n",
    "    \n",
    "    +----------------+-------+-------+\n",
    "    | Statistics     | Value |     % |\n",
    "    +----------------+-------+-------+\n",
    "    | N              | 7,000 |       |\n",
    "    | Target         |   581 |  8.3% |\n",
    "    | True Positive  |   513 |  7.3% |\n",
    "    | True Negative  | 6,412 | 91.6% |\n",
    "    | False Positive |     7 |  0.1% |\n",
    "    | False Negative |    68 |  1.0% |\n",
    "    | Precision      |       | 98.7% |\n",
    "    | Recall         |       | 88.3% |\n",
    "    | Accuracy       |       | 98.9% |\n",
    "    | F1-Score       |       | 93.2% |\n",
    "    +----------------+-------+-------+\n",
    "        \n",
    "    '''\n",
    "    # Calculate all parameters.\n",
    "    tn0, fp0, fn0, tp0 = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tn1, fp1, fn1, tp1 = np.r_[tn0, fp0, fn0, tp0]/len(y_true)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    N0, N1 = int(sum(y_true)), sum(y_true)/len(y_true)\n",
    "    decimal = max(int(decimal), 0)\n",
    "    fmt1, fmt2 = \"{:,d}\".format, (\"{:.\" + f\"{decimal}\" + \"%}\").format\n",
    "    \n",
    "    # Set up summary table\n",
    "    t = PrettyTable(['Statistics', 'Value', \"%\"])\n",
    "    t.align[\"Statistics\"] = \"l\"\n",
    "    t.align[\"Value\"] = \"r\"\n",
    "    t.align[\"%\"] = \"r\"\n",
    "    t.add_row(['N' , fmt1(len(y_true)), \"\"])\n",
    "    t.add_row(['Target' , fmt1(N0), fmt2(N1)])\n",
    "    t.add_row(['True Positive' , fmt1(tp0), fmt2(tp1)])\n",
    "    t.add_row(['True Negative' , fmt1(tn0), fmt2(tn1)])\n",
    "    t.add_row(['False Positive', fmt1(fp0), fmt2(fp1)])\n",
    "    t.add_row(['False Negative', fmt1(fn0), fmt2(fn1)])\n",
    "    t.add_row([\"Precision\", \"\", fmt2(tp0/np.fmax(fp0+tp0,1))])\n",
    "    t.add_row([\"Recall\"   , \"\", fmt2(tp0/np.fmax(fn0+tp0,1))])\n",
    "    t.add_row([\"Accuracy\" , \"\", fmt2((tp0+tn0)/len(y_true))])\n",
    "    t.add_row([\"F1-Score\" , \"\", fmt2(f1)])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rule(rule, decimal=2):\n",
    "    \n",
    "    '''\n",
    "    Prints subrule(s).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rules : collections.namedtuple\n",
    "        A tuple subclass named \"Rule\" (typename).\n",
    "    \n",
    "    decimal : int, default=1\n",
    "        Decimal place for %.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> print_rule(rule, decimal=4)\n",
    "    \n",
    "    +------+-------------+------+--------+\n",
    "    | Item | Variable    | Sign |  Value |\n",
    "    +------+-------------+------+--------+\n",
    "    |  1   | Variable_01 |  ==  |    xxx |\n",
    "    |  2   | Variable_02 |  <=  | 1.0000 |\n",
    "    |  3   | Variable_03 |  ==  |     xx |\n",
    "    +------+-------------+------+--------+\n",
    "    \n",
    "    '''\n",
    "    # Set up summary table\n",
    "    t = PrettyTable([\"Item\", 'Variable', 'Sign', \"Value\"])\n",
    "    t.align[\"Item\"] = \"c\"\n",
    "    t.align[\"Variable\"] = \"l\"\n",
    "    t.align[\"Sign\"] = \"c\"\n",
    "    t.align[\"Value\"] = \"r\"\n",
    "    decimal = max(int(decimal),0)\n",
    "    fmt = (\"{:,.\" +  f\"{decimal}\" + \"f}\").format\n",
    "    for n,h in enumerate(rule.rule,1):\n",
    "        var, sign, value = h\n",
    "        if isinstance(value, (int,float)): value = fmt(value)\n",
    "        t.add_row([n, var, sign, value])\n",
    "    print(\"Operator: \",rule.operator)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rules(eval_set, rules, operator=\"or\"):\n",
    "    \n",
    "    '''\n",
    "    Evaluate set of rules.\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    eval_set : list of tuples\n",
    "        A list of tuples, where first item is X of shape (n_samples, \n",
    "        n_features) and the seccond item is y of shape (n_samples,) \n",
    "        e.g. [(X0, y0), (X1, y1)]. \n",
    "        \n",
    "    rules : list of namedtuple\n",
    "        A list of tuple subclass named \"Rule\" (typename).\n",
    "        \n",
    "    operator : {\"or\", \"and\"}, default=\"or\"\n",
    "        If \"or\", \"or\" operator is assigned as a relationship between \n",
    "        antecedent and consequent rules (n_operands > 0). If \"and\", \n",
    "        \"and\" operator is assigned (n_operands > 1).    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    EvalResults : collections.namedtuple\n",
    "        A dictionary subclass that contains fields as follows:\n",
    "    \n",
    "        Field      Description\n",
    "        -----      -----------\n",
    "        sample     Numer of samples\n",
    "        target     Number of targets\n",
    "        tp         True positive\n",
    "        fp         False positive\n",
    "        fn         False negative\n",
    "        tn         True negative\n",
    "        recall     Recall scores\n",
    "        precision  Precision scores\n",
    "        f1         F1 scores\n",
    "        accuray    Accuracy\n",
    "        \n",
    "        Note: all outputs are arranged according to `eval_set`\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(eval_set, list):\n",
    "        raise ValueError(f\"`eval_set` has to be list. \"\n",
    "                         f\"Got {type(eval_set)} instead.\")\n",
    "    \n",
    "    keys = [\"sample\", \"target\", \"tp\", \"fp\", \"fn\", \"tn\", \n",
    "            \"recall\", \"precision\", \"f1\", \"accuracy\"]\n",
    "    data = dict([(key,[]) for key in keys])\n",
    "\n",
    "    for X,y in eval_set:\n",
    "        \n",
    "        # Determine `y_pred` given rule(s).\n",
    "        alert = np.vstack([rule_alert(X, rule) for rule in rules]).T\n",
    "        if operator==\"or\": y_pred = (alert.sum(1)>0).astype(int)\n",
    "        else: y_pred = (alert.sum(1)==len(rules)).astype(int)\n",
    "        y_true = np.array(y).astype(int)\n",
    "        \n",
    "        # Calculate all metrics.\n",
    "        csc_true = csc(y_true.reshape(-1,1)).copy()\n",
    "        csc_pred = csc(y_pred.reshape(-1,1)).copy()\n",
    "        args = (csc_true, csc_pred)\n",
    "        tp, fp, fn, tn, recall, precision, f1 = cfm_base_csc(*args)\n",
    "        n_samples, n_targets = len(y_true), sum(y_true)\n",
    "        accuracy = (tp+tn)/len(y_true)\n",
    "        \n",
    "        data[\"sample\"] += [n_samples]\n",
    "        data[\"target\"] += [n_targets]\n",
    "        data[\"tp\"] += [tp[0]]\n",
    "        data[\"fp\"] += [fp[0]]\n",
    "        data[\"fn\"] += [fn[0]]\n",
    "        data[\"tn\"] += [tn[0]]\n",
    "        data[\"precision\"] += [precision[0]]\n",
    "        data[\"recall\"] += [recall[0]]\n",
    "        data[\"f1\"] += [f1[0]]\n",
    "        data[\"accuracy\"] += [accuracy[0]]\n",
    "        \n",
    "    return namedtuple(\"EvalResults\", keys)(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rule(subrules, operator=\"and\"):\n",
    "    '''\n",
    "    Create a rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subrules : list of tuples\n",
    "        A list of subrules in the following format [(\"variable\",\n",
    "        \"sign\",\"value\")], e.g. [(\"var\",\"<=\",1000)].\n",
    "    \n",
    "    operator : {\"or\", \"and\"}, default=\"or\"\n",
    "        If \"or\", \"or\" operator is assigned as a relationship between \n",
    "        antecedent and consequent rules. If \"and\", \"and\" operator is \n",
    "        assigned.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Rule : list of namedtuple\n",
    "        A list of tuple subclass named \"Rule\" (typename).\n",
    "        \n",
    "    '''\n",
    "    return namedtuple(\"Rule\", [\"rule\",\"operator\"])(subrules,operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google.colab\n",
    "Only execute this cell when use on google colab platform (colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Nak007/AssoruleMining\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount with google drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/dirve')\n",
    "# Import other libraries required. All *.py will be \n",
    "# stored under the following location i.e. '/content/example.py'.\n",
    "!git clone 'http://github.com/Nak007/AssoruleMining.git'\n",
    "!pip install PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, sys\n",
    "# try: sys.path.append('/content/AssoruleMining')\n",
    "# except: pass\n",
    "# from AssoruleMining import *\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('card_transdata_10K.txt', sep=\"|\")\n",
    "y = X.pop(\"fraud\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"repeat_retailer\", \"used_chip\", \"used_pin_number\", \"online_order\"]:\n",
    "    X[var] = np.where(X[var]==1,\"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **`define_dtype`** to convert columns in `X` to possible dtypes which are `float32`, `int32`, `category`, and `object`. However, it ignores columns, whose dtype is either np.datetime64 or np.timedelta64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = define_dtype(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXL9lUApPTVk"
   },
   "source": [
    "Split data into **train**, and **test** sets [(**`train_test_split`**)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1614135192095,
     "user": {
      "displayName": "Danusorn Sitdhirasdr",
      "photoUrl": "",
      "userId": "00479571870945710380"
     },
     "user_tz": -420
    },
    "id": "YGsdoNNxYO0k"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discretize `X`, we use **`discretize`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr_X1, rules1 = discretize(X_train, n_cutoffs=20)\n",
    "discr_X1, rules1 = discretize(criterion=\"tree\", decimal=3, ).transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of rules (1)\n",
    "- Antecedent rule is mutually exclusive to consequent rule (assumption).\n",
    "- Training samples captured by antecedent rule(s) are excluded before determining the next consequent rule.\n",
    "- This approach stops when the evaluating metric is deemed satisfactory or not improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso1 = AssoRuleMining(metric=\"f1\", operator=\"and\", n_jobs=3, n_batches=5).fit(discr_X1, y_train, rules=rules1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**info** (attribute) : a summary table that comes in a form of `dict` with keys as column headers. It can be imported into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(asso1.info).sort_values(by=[\"f1_score\",\"n_features\"], ascending=[False,True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we focus on `f1-score`. Hence, we choose rule(s) that has the highest `f1-score` accordingly. In the case of a tie, we select `variable`, whose number of features is the lowest. This is for the sake of reducing rule complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create $1^{st}$ rule, we use **`RuleToFeature`** to convert rules into features array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule1_index = 124\n",
    "FirstRule = RuleToFeature(X_train, asso1.asso_results_, which_rules=[rule1_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **`print_rule`** to tabulate rule information i.e. intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rule(FirstRule[1][rule1_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before determining next rule, we exclude only instances that meet the $1^{st}$ rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = FirstRule[0].values.ravel()\n",
    "X2 = X_train.loc[~index] \n",
    "y2 = y_train[~index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr_X2, rules2 = discretize(X2, n_cutoffs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso2 = AssoRuleMining(metric=\"f1\", operator=\"and\", n_jobs=3).fit(discr_X2, y2, rules=rules2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(asso2.info).sort_values(by=[\"f1_score\",\"n_features\"], ascending=[False,True]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create $2^{nd}$ rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2_index = 122\n",
    "SecondRule = RuleToFeature(X_train, asso2.asso_results_, which_rules=[rule2_index])\n",
    "print_rule(SecondRule[1][rule2_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary on `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(np.hstack((FirstRule[0], SecondRule[0])).T)[0,1]\n",
    "print(\"Correlation between 1st and 2nd rules : {:.2%}\".format(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the correlation is insignificant i.e. 2.06%, we will ignore adding the negation of the first rule to the second rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (FirstRule[0].values | SecondRule[0].values)\n",
    "print_stats(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary on `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = (RuleToFeature(X_test, asso1.asso_results_, which_rules=[rule1_index])[0].values |\n",
    "               RuleToFeature(X_test, asso2.asso_results_, which_rules=[rule2_index])[0].values)\n",
    "print_stats(y_test, y_pred_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use **`evaluate_rules`** to evaluate all datasets at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules=[asso1.asso_results_[rule1_index], asso2.asso_results_[rule2_index]]\n",
    "evaluate_rules([(X_train,y_train), (X_test,y_test)], rules=rules, operator=\"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of rules (2)\n",
    "- Convert all rules into features.\n",
    "- Determine combinations of rules that optimize the evaluating metric. This can be used as validation of rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting variables that capture target more than `x`% helps in reducing features, whose impact is insignificant. For this example, we use 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_rules = np.array(asso1.info[\"variable\"])[np.array(asso1.info[\"p_target\"])>0.01]\n",
    "discr_X3, rules3 = RuleToFeature(X_train, asso1.asso_results_, which_rules=which_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso3 = AssoRuleMining(metric=\"f1\", operator=\"or\", n_jobs=4, n_batches=5)\n",
    "asso3.fit(discr_X3, y_train, rules=rules3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(asso3.info).sort_values(by=[\"f1_score\", \"n_features\"], ascending=[False, True]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select rule set from `variable 0` due to low correlations between rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule3_index = 0\n",
    "selected_rules = asso3.asso_results_[rule3_index].features\n",
    "np.round(RuleToFeature(X_train, asso1.asso_results_, \n",
    "                       which_rules=selected_rules)[0].corr(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all selected rules and their subrules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,r in zip(asso3.asso_results_[rule3_index].features,\n",
    "               asso3.asso_results_[rule3_index].rule):\n",
    "    print(\"Rule number: \",n); print_rule(r); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary on `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = RuleToFeature(X_train, asso1.asso_results_, which_rules=selected_rules)[0].sum(1)>0\n",
    "print_stats(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary on `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = RuleToFeature(X_test, asso1.asso_results_, which_rules=selected_rules)[0].sum(1)>0\n",
    "print_stats(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [asso1.asso_results_[n] for n in selected_rules]\n",
    "evaluate_rules([(X_train,y_train), (X_test,y_test)], rules=rules, operator=\"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of rules (3)\n",
    "- Create set of rules of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subrules = [('ratio_to_median_purchase_price', '>=', 4.065), \n",
    "            ('online_order', '==', 'yes'), \n",
    "            ('used_pin_number', '==', 'no')]\n",
    "operator = 'and'\n",
    "rule1 = create_rule(subrules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subrules = [('distance_from_home', '>=', 96.4349), \n",
    "            ('used_chip', '==', 'no'), \n",
    "            ('online_order', '==', 'yes'), \n",
    "            ('used_pin_number', '==', 'no')]\n",
    "operator = 'and'\n",
    "rule2 = create_rule(subrules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rules([(X_train,y_train), (X_test,y_test)], \n",
    "               rules=[rule1, rule2], operator=\"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of rules (4)\n",
    "- Extract paths in each tree and turn them into features.\n",
    "- Determine combinations of rules that optimize the evaluating metric. This can be used as validation of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'AssoRuleMining.ipynb',\n",
       " 'cluster_visualization.py',\n",
       " 'feat_dep.txt.gz',\n",
       " 'feat_prod_hldg.txt.gz',\n",
       " 'freelance_fico.txt',\n",
       " 'NTB_sa_employee_fico.txt',\n",
       " 'ntc_202207_send_nak.txt',\n",
       " 'ntc_all_features.txt.gz',\n",
       " 'ntc_audit_rl_combine_rest_202208.pkl',\n",
       " 'replicated_yi_data_202208.txt',\n",
       " 'varclus.py',\n",
       " 'varclus_colab.ipynb']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = pd.read_csv(\"replicated_yi_data_202208.txt\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "เจ้าของกิจการ                     48598\n",
       "อาชีพอิสระ                        25987\n",
       "พนักงานบริษัทเอกชน                10931\n",
       "รับจ้าง/พนักงานรายวัน/ชั่วคราว     4520\n",
       "นักเรียน/นักศึกษา                   876\n",
       "พนักงานรัฐวิสาหกิจ                  798\n",
       "พ่อบ้าน/แม่บ้าน                     663\n",
       "รับราชการ                           649\n",
       "เกษตรกร                             460\n",
       "เกษียณ                               19\n",
       "Name: current_occupation, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk.loc[kk[\"modl_seg\"]==\"NTC\",\"current_occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = pd.read_pickle('ntc_audit_rl_combine_rest_202208.pkl')\n",
    "audit = audit.loc[audit[[\"audit_rl_flg\",\"audit_arm_flg\"]].sum(1)>0,\"appkey\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = pd.read_csv(\"replicated_yi_data_202208.txt\", sep=\"|\")\n",
    "yi = yi.loc[((yi[\"modl_seg\"]==\"NTC\") \n",
    "             & (yi[\"current_occupation\"]==\"เจ้าของกิจการ\")\n",
    "            )].reset_index(drop=True)\n",
    "yi = yi.drop(columns=[\"modl_seg\",\n",
    "                      \"dpd60plus_in_3m\",\n",
    "                      \"dpd30plus_in_2m\",\n",
    "                      \"dpd90plus_in_4m\",\n",
    "                      \"fpd\", \"fpd_2\"]).fillna(0)\n",
    "yi[\"YYYY-MM\"] = yi[\"YYYY-MM\"].str.replace(\"-\",\"\").astype(int)\n",
    "appkey = yi[\"appkey\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = list(set(audit).intersection(appkey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_csv('feat_dep.txt.gz', sep=\"|\").rename(columns={\"mth\":\"YYYY-MM\"})\n",
    "a1 = a1.loc[a1[\"appkey\"].isin(audit)].reset_index(drop=True)\n",
    "a2 = pd.read_csv('feat_prod_hldg.txt.gz', sep=\"|\").drop(columns=\"flag\")\n",
    "a2 = a2.loc[a2[\"appkey\"].isin(audit)].reset_index(drop=True)\n",
    "a2[\"YYYY-MM\"] = a2[\"YYYY-MM\"].str.replace(\"-\",\"\").astype(int)\n",
    "a3 = a1.merge(a2, how=\"outer\", on=[\"appkey\",\"ip_id\",\"YYYY-MM\"])\n",
    "a3 = a3.merge(yi, how=\"left\", on=[\"appkey\",\"ip_id\",\"YYYY-MM\"]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X0 = pd.read_csv('NTB_sa_employee_fico.txt', sep=\"|\").fillna(0)\n",
    "# a0 = pd.read_pickle(\"ntc_audit_rl_combine_rest_202208.pkl\")\n",
    "# appkey = a0[\"appkey\"].values\n",
    "# appkey = appkey[a0[[\"audit_rl_flg\", \"audit_arm_flg\"]].sum(1)>0].tolist()\n",
    "X0 = a3.drop(columns=[\"appkey\",\"ip_id\",\"YYYY-MM\"]).copy()\n",
    "y0 = X0.pop(\"dpd60plus_in_3m\").values\n",
    "X0[\"income_increase_percentage\"] = X0[\"income_increase_percentage\"].str.replace(\"'\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT ==> sex\n",
      "CAT ==> current_occupation\n",
      "CAT ==> highest_education\n",
      "CAT ==> curr_characteristics\n"
     ]
    }
   ],
   "source": [
    "drop = []\n",
    "for c in X0.columns:\n",
    "    if sum(X0[c]==np.inf)>0:\n",
    "        print(\"INF ==> \",c)\n",
    "        f = (X0[c]==np.inf)\n",
    "        X0[c] = np.where(f,X0[c][f==False].max(),X0[c])\n",
    "    elif X0[c].dtype==\"O\":\n",
    "        print(\"CAT ==>\",c)\n",
    "        drop.append(c)\n",
    "        for n in set(X0[c]):\n",
    "            X0[f\"cat_{n}\"] = np.where(X0[c]==n,1,0)\n",
    "X0.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "pred_features = []\n",
    "for c in X0.columns:\n",
    "    try:\n",
    "        gini = 2*roc_auc_score(y0, X0[c].values)-1\n",
    "        if abs(gini) >= 0.1: pred_features.append(c)\n",
    "    except: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X0.drop(columns=[\"credit_rmn_to_tot_ln_amt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X0[pred_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv('ntc_all_features.txt.gz', sep=\"|\").drop(columns=[\"ip_id\",\"appkey\"])\n",
    "# X0 = X.loc[X[\"YYYY-MM\"]!=\"2022-07\"].reset_index(drop=True)\n",
    "# y0 = X0.pop(\"dpd60plus_in_3m\").values\n",
    "# X1 = X.loc[X[\"YYYY-MM\"]==\"2022-07\"].reset_index(drop=True)\n",
    "# y1 = X1.pop(\"dpd60plus_in_3m\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c0 = np.array(X0.columns.str.contains(\"|\".join((\"bc_\",\"log_\"))))\n",
    "# c1 = np.array([True if X0[var].dtype==\"O\" else False for var in X0.columns])\n",
    "# c2 = X0.columns[(c0  + c1)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X0.fillna(0), y0, test_size=0.3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_ouput(data, rules):\n",
    "    func = {\"==\": np.equal, \n",
    "        \"!=\": np.not_equal,\n",
    "        \"<\" : np.less, \n",
    "        \">=\": np.greater_equal, \n",
    "        \"<=\": np.less_equal,\n",
    "        \">\" : np.greater}\n",
    "    flag = np.ones(len(data)).astype(bool)\n",
    "    for r,s,x2 in rules:\n",
    "        x1 = data[r].values\n",
    "        flag &= func[s](x1, x2)\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = X0.copy()\n",
    "ay = y0.copy()\n",
    "\n",
    "use = np.ones(len(aX)).astype(bool)\n",
    "rules = dict()\n",
    "\n",
    "for n in range(1,15):\n",
    "\n",
    "    print(n,\"Number of samples: {:,d}\".format(sum(use)))\n",
    "\n",
    "    if (sum(use)==0) or (ay.sum()==0): break\n",
    "        \n",
    "    kwds = dict(max_depth=None,  \n",
    "                min_samples_leaf=int(sum(use)*0.01),\n",
    "                max_features=aX.shape[1], \n",
    "                random_state=0)\n",
    "    Tree  = DecisionTreeClassifier(**kwds).fit(aX, ay)\n",
    "    paths = GetDecisionPaths(min_precision=0.1).fit(Tree, list(aX))\n",
    "\n",
    "    k = np.argmax(paths.info[\"precision\"])\n",
    "    selected_path = paths.decision_paths[paths.info[\"key\"][k]]\n",
    "    rules[f\"Rule_{n}\"] = selected_path\n",
    "\n",
    "    output = rule_ouput(aX, selected_path.rule)\n",
    "    use = output==False\n",
    "    aX = aX[use].copy()\n",
    "    ay = ay[use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = {\"n_samples\":[],\n",
    "        \"n_targets\":[],\n",
    "        \"precision\":[],\n",
    "        \"f1_score\" :[]}\n",
    "\n",
    "for key in rules.keys():\n",
    "    info[\"n_samples\"] += [rules[key].n_samples[-1]]\n",
    "    info[\"n_targets\"] += [rules[key].n_targets[-1]]\n",
    "    info[\"precision\"] += [rules[key].precision[-1]]\n",
    "    info[\"f1_score\"]  += [rules[key].f1_score[-1]]\n",
    "#     for n in rules[key].rule:\n",
    "#         print(n)\n",
    "#     print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = {\"==\": np.equal, \n",
    "        \"!=\": np.not_equal,\n",
    "        \"<\" : np.less, \n",
    "        \">=\": np.greater_equal, \n",
    "        \"<=\": np.less_equal,\n",
    "        \">\" : np.greater}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = X_test.copy()\n",
    "# output = {\"n_targets\":[], \n",
    "#           \"n_samples\":[]}\n",
    "# m_flag = np.zeros(len(data)).astype(bool)\n",
    "# for key in rules.keys():\n",
    "#     flag = np.ones(len(data)).astype(bool)\n",
    "#     for r,s,v in rules[key].rule:\n",
    "#         flag &= func[s](data[r].values,v)\n",
    "#     m_flag |= flag\n",
    "#     output[\"n_samples\"].append(sum(m_flag))\n",
    "#     output[\"n_targets\"].append(sum(y_test[m_flag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k00 = pd.DataFrame(output)\n",
    "# k00[\"precision\"] = k00[\"n_targets\"]/k00[\"n_samples\"]\n",
    "# k00[\"recall\"] = k00[\"n_targets\"]/sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pp[\"n_targets\"].values)/np.cumsum(pp[\"n_samples\"].values), marker=\"o\", label=\"Precision\")\n",
    "plt.plot(np.cumsum(pp[\"n_targets\"].values)/sum(y0), marker=\"o\", label=\"Recall\")\n",
    "# plt.plot(k00[\"precision\"], marker=\"o\")\n",
    "# plt.plot(k00[\"recall\"], marker=\"o\")\n",
    "# plt.axhline(y0.mean(), ls=\"--\")\n",
    "# plt.axvline(15)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "p = (np.cumsum(pp[\"n_targets\"].values)/np.cumsum(pp[\"n_samples\"].values))[i]\n",
    "r = (np.cumsum(pp[\"n_targets\"].values)/sum(y0))[i]\n",
    "print(\"precision {:,.2%}\".format(p))\n",
    "print(\"recall {:,.2%}\".format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert rules to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in rules.keys():\n",
    "#     for r,s,v in rules[key].rule:\n",
    "#         X_train[key] = func[s](X_train[r].values,v)\n",
    "#         X_test[key] = func[s](X_test[r].values,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for t,key in enumerate(rules.keys()):\n",
    "#     if t >= 6: break\n",
    "#     for n in rules[key].rule:\n",
    "#         print(n)\n",
    "#     print(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of rules (5)\n",
    "- Extract paths in each tree and turn them into features.\n",
    "- Determine combinations of rules that optimize the evaluating metric. This can be used as validation of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6515951891ec4f0f91810e1a7f20c5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTMLMath(value='Calculating . . .'), HTMLMath(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwds = dict(max_depth=None,\n",
    "            max_features=X0.shape[1], \n",
    "            random_state=0, \n",
    "            min_samples_leaf=0.01, \n",
    "            class_weight=\"balanced\")\n",
    "\n",
    "a = TreeRuleMining(DecisionTreeClassifier(**kwds), \n",
    "                   exclude=False, \n",
    "                   metric=\"precision\", \n",
    "                   max_iter=12, \n",
    "                   cal_max_depth=True).fit(X0,y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = a.evaluate(X0, y0, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b7335f06d0>]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f.values[:,2], marker=\"o\")\n",
    "plt.plot(f.values[:,3], marker=\"o\")\n",
    "plt.plot(f.values[:,1]/len(X0), marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator:  and\n",
      "+------+-----------------------------+------+-----------+\n",
      "| Item | Variable                    | Sign |     Value |\n",
      "+------+-----------------------------+------+-----------+\n",
      "|  1   | avg_bal_min_4m              |  <=  |    583.60 |\n",
      "|  2   | dr_txn_std_6m               |  >   |     26.67 |\n",
      "|  3   | max_last_payment_date_ndays |  <=  | 19,187.50 |\n",
      "|  4   | avg_bal_median_4m           |  <=  |    437.06 |\n",
      "|  5   | dr_txn_std_12m              |  >   |     81.88 |\n",
      "|  6   | atm_rcm_cdm_amt_lag12       |  <=  |  3,850.00 |\n",
      "+------+-----------------------------+------+-----------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+--------------------------+------+--------+\n",
      "| Item | Variable                 | Sign |  Value |\n",
      "+------+--------------------------+------+--------+\n",
      "|  1   | avg_bal_min_4m           |  <=  | 653.10 |\n",
      "|  2   | dr_txn_std_6m            |  >   |  26.39 |\n",
      "|  3   | atm_rcm_cdm_txn_std_6m   |  >   |   5.27 |\n",
      "|  4   | k_plus_txn_lag06         |  >   |  21.50 |\n",
      "|  5   | age_of_applicant_(years) |  <=  |  37.50 |\n",
      "|  6   | mny_tfr_tot_txn_6/6_mean |  <=  |   1.13 |\n",
      "|  7   | dr_txn_std_6m            |  <=  |  43.20 |\n",
      "+------+--------------------------+------+--------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+-----------------------------+------+------------+\n",
      "| Item | Variable                    | Sign |      Value |\n",
      "+------+-----------------------------+------+------------+\n",
      "|  1   | dr_txn_std_12m              |  >   |      41.55 |\n",
      "|  2   | avg_bal_min_4m              |  <=  |   2,036.27 |\n",
      "|  3   | r_k_plus_amt_lag01_p_min_3m |  >   |       1.63 |\n",
      "|  4   | atm_rcm_cdm_txn_std_12m     |  >   |       4.67 |\n",
      "|  5   | r_cr_amt_max_3m_p_12m       |  >   |       0.78 |\n",
      "|  6   | fico_score                  |  <=  |     633.00 |\n",
      "|  7   | loan_amount_x               |  >   | 171,500.00 |\n",
      "|  8   | k_plus_txn_min_6m           |  <=  |     106.50 |\n",
      "+------+-----------------------------+------+------------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+-----------------------------------+------+-----------+\n",
      "| Item | Variable                          | Sign |     Value |\n",
      "+------+-----------------------------------+------+-----------+\n",
      "|  1   | avg_bal_min_4m                    |  <=  |    986.12 |\n",
      "|  2   | dr_txn_std_12m                    |  >   |     26.85 |\n",
      "|  3   | max_last_payment_date_ndays       |  <=  | 19,186.50 |\n",
      "|  4   | kplus_shop_f_mean_last_6mth       |  <=  |      0.92 |\n",
      "|  5   | r_dr_amt_mean_3m_p_12m            |  <=  |      3.44 |\n",
      "|  6   | nbr_pd_hldg_9/3_mean              |  >   |      0.99 |\n",
      "|  7   | dr_amt_min_12m                    |  <=  |  6,453.67 |\n",
      "|  8   | r_atm_rcm_cdm_txn_lag01_p_mean_3m |  >   |      0.81 |\n",
      "|  9   | max_last_payment_date_ndays       |  >   |     48.50 |\n",
      "|  10  | avg_bal_median_4m                 |  >   |    418.48 |\n",
      "+------+-----------------------------------+------+-----------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+------------------------------+------+-----------+\n",
      "| Item | Variable                     | Sign |     Value |\n",
      "+------+------------------------------+------+-----------+\n",
      "|  1   | avg_bal_min_4m               |  <=  |    533.56 |\n",
      "|  2   | dr_txn_std_3m                |  >   |     27.70 |\n",
      "|  3   | r_k_plus_amt_median_3m_p_12m |  <=  |     11.40 |\n",
      "|  4   | max_last_payment_date_ndays  |  <=  | 19,186.50 |\n",
      "|  5   | avg_bal_lag01                |  <=  |    380.20 |\n",
      "|  6   | cr_txn_sum_6m                |  <=  |    452.50 |\n",
      "|  7   | bp_tot_txn_3/3_mean          |  >   |      1.05 |\n",
      "+------+------------------------------+------+-----------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+-----------------------------+------+-----------+\n",
      "| Item | Variable                    | Sign |     Value |\n",
      "+------+-----------------------------+------+-----------+\n",
      "|  1   | avg_bal_min_6m              |  <=  |    996.57 |\n",
      "|  2   | k_plus_txn_max_6m           |  >   |    127.50 |\n",
      "|  3   | max_last_payment_date_ndays |  <=  | 19,186.50 |\n",
      "|  4   | dr_txn_mean_6m              |  <=  |    228.08 |\n",
      "|  5   | avg_bal_lag03               |  <=  |    569.11 |\n",
      "|  6   | cr_txn_std_3m               |  <=  |     51.44 |\n",
      "|  7   | r_dr_txn_max_3m_p_12m       |  >   |      0.73 |\n",
      "|  8   | r_k_plus_amt_sum_6m_p_12m   |  >   |      0.55 |\n",
      "|  9   | nbr_pd_hldg_6/6_mean        |  <=  |      1.63 |\n",
      "|  10  | atm_rcm_cdm_amt_lag03       |  <=  |  7,550.00 |\n",
      "|  11  | cr_txn_std_4m               |  <=  |     20.64 |\n",
      "+------+-----------------------------+------+-----------+\n",
      "\n",
      "\n",
      "Operator:  and\n",
      "+------+------------------------------+------+----------+\n",
      "| Item | Variable                     | Sign |    Value |\n",
      "+------+------------------------------+------+----------+\n",
      "|  1   | dr_txn_std_6m                |  >   |    47.02 |\n",
      "|  2   | enquires_last_6_months       |  >   |     6.50 |\n",
      "|  3   | kplus_shop_f_mean_last_12mth |  <=  |     0.19 |\n",
      "|  4   | k_plus_txn_min_6m            |  >   |    59.50 |\n",
      "|  5   | atm_rcm_cdm_amt_mean_4m      |  >   | 9,467.50 |\n",
      "|  6   | r_cr_amt_median_6m_p_12m     |  >   |     1.58 |\n",
      "+------+------------------------------+------+----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,8):\n",
    "    print_rule(a.rules[f\"Rule_{n}\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = X0.copy()\n",
    "ay = y0.copy()\n",
    "kwds = dict(n_estimators=10,\n",
    "            max_depth=None,  \n",
    "            min_samples_leaf=int(sum(ay)*0.01),\n",
    "            max_features=\"sqrt\", \n",
    "            random_state=0, \n",
    "            bootstrap=True)\n",
    "Tree  = RandomForestClassifier(**kwds).fit(aX, ay)\n",
    "paths = GetDecisionPaths(min_precision=0.4).fit(Tree, list(aX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_rules['T0-5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_X, tree_rules = RuleToFeature(aX, paths.decision_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso1 = AssoRuleMining(metric=\"f1\", operator=\"or\", \n",
    "                       n_jobs=-1, n_batches=5).fit(converted_X, ay, rules=tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(asso1.info).sort_values(by=[\"f1_score\",\"n_features\"], ascending=[False,True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we focus on `f1-score`. Hence, we choose rule(s) that has the highest `f1-score` accordingly. In the case of a tie, we select `variable`, whose number of features is the lowest. This is for the sake of reducing rule complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create $1^{st}$ rule, we use **`RuleToFeature`** to convert rules into features array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule1_index = \"T5-456\"\n",
    "FirstRule = RuleToFeature(X0, asso1.asso_results_, which_rules=[\"T5-456\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstRule[0].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso1.asso_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **`print_rule`** to tabulate rule information i.e. intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rule(FirstRule[1][rule1_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = np.hstack(flags).sum(1)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(flags.astype(int) - pp.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
