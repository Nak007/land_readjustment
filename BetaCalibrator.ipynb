{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Available methods are the followings:\n",
    "[1] BetaCalibration\n",
    "[2] ABM_BetaCal\n",
    "[3] AB_BetaCal\n",
    "[4] AM_BetaCal\n",
    "[5] Sigmoid_Cal\n",
    "[6] ModifiedLogistic\n",
    "[7] calibration_metrics\n",
    "\n",
    "Authors: Danusorn Sitdhirasdr <danusorn.si@gmail.com>\n",
    "versionadded:: 30-10-2025\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.metrics import brier_score_loss, log_loss, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import column_or_1d, check_consistent_length\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils.validation import (check_array, check_is_fitted, \n",
    "                                      _check_sample_weight, check_X_y)\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import font_manager as fm, cm\n",
    "from matplotlib.ticker import (FixedLocator, \n",
    "                               FixedFormatter, \n",
    "                               StrMethodFormatter,\n",
    "                               FuncFormatter)\n",
    "\n",
    "paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "for font_path in paths:\n",
    "    if font_path.find(\"Hiragino Sans GB W3\")>-1:\n",
    "        fm.fontManager.addfont(font_path)\n",
    "        prop = fm.FontProperties(fname=font_path)\n",
    "        plt.rcParams['font.family'] = 'sans-serif'\n",
    "        plt.rcParams['font.sans-serif'] = prop.get_name()\n",
    "        plt.rcParams.update({'font.family':'sans-serif'})\n",
    "        plt.rcParams.update({'font.sans-serif':prop.get_name()})\n",
    "        \n",
    "plt.rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d41e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"BetaCalibration\",\n",
    "           \"ABM_BetaCal\",\n",
    "           \"AB_BetaCal\",\n",
    "           \"AM_BetaCal\", \n",
    "           \"Sigmoid_Cal\",\n",
    "           \"ModifiedLogistic\", \n",
    "           \"calibration_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateParams:\n",
    "    \n",
    "    '''Validate parameters'''\n",
    "    \n",
    "    def Interval(self, Param, Value, dtype=int, \n",
    "                 left=None, right=None, closed=\"both\"):\n",
    "\n",
    "        '''\n",
    "        Validate numerical input.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Param : str\n",
    "            Parameter's name\n",
    "\n",
    "        Value : float or int\n",
    "            Parameter's value\n",
    "\n",
    "        dtype : {int, float}, default=int\n",
    "            The type of input.\n",
    "\n",
    "        left : float or int or None, default=None\n",
    "            The left bound of the interval. None means left bound is -∞.\n",
    "\n",
    "        right : float, int or None, default=None\n",
    "            The right bound of the interval. None means right bound is +∞.\n",
    "\n",
    "        closed : {\"left\", \"right\", \"both\", \"neither\"}\n",
    "            Whether the interval is open or closed. Possible choices are:\n",
    "            - \"left\": the interval is closed on the left and open on the \n",
    "              right. It is equivalent to the interval [ left, right ).\n",
    "            - \"right\": the interval is closed on the right and open on the \n",
    "              left. It is equivalent to the interval ( left, right ].\n",
    "            - \"both\": the interval is closed.\n",
    "              It is equivalent to the interval [ left, right ].\n",
    "            - \"neither\": the interval is open.\n",
    "              It is equivalent to the interval ( left, right ).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Value : float or int\n",
    "            Parameter's value\n",
    "\n",
    "        '''\n",
    "        Options = {\"left\"    : (np.greater_equal, np.less), # a<=x<b\n",
    "                   \"right\"   : (np.greater, np.less_equal), # a<x<=b\n",
    "                   \"both\"    : (np.greater_equal, np.less_equal), # a<=x<=b\n",
    "                   \"neither\" : (np.greater, np.less)} # a<x<b\n",
    "\n",
    "        f0, f1 = Options[closed]\n",
    "        c0 = \"[\" if f0.__name__.find(\"eq\")>-1 else \"(\" \n",
    "        c1 = \"]\" if f1.__name__.find(\"eq\")>-1 else \")\"\n",
    "        v0 = \"-∞\" if left is None else str(dtype(left))\n",
    "        v1 = \"+∞\" if right is None else str(dtype(right))\n",
    "        if left  is None: left  = -np.inf\n",
    "        if right is None: right = +np.inf\n",
    "        interval = \", \".join([c0+v0, v1+c1])\n",
    "        tuples = (Param, dtype.__name__, interval, Value)\n",
    "        err_msg = \"%s must be %s or in %s, got %s \" % tuples    \n",
    "\n",
    "        if isinstance(Value, dtype):\n",
    "            if not (f0(Value, left) & f1(Value, right)):\n",
    "                raise ValueError(err_msg)\n",
    "        else: raise ValueError(err_msg)\n",
    "        return Value\n",
    "\n",
    "    def StrOptions(self, Param, Value, options, dtype=str):\n",
    "\n",
    "        '''\n",
    "        Validate string or boolean inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Param : str\n",
    "            Parameter's name\n",
    "            \n",
    "        Value : float or int\n",
    "            Parameter's value\n",
    "\n",
    "        options : set of str\n",
    "            The set of valid strings.\n",
    "\n",
    "        dtype : {str, bool}, default=str\n",
    "            The type of input.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Value : float or int\n",
    "            Parameter's value\n",
    "\n",
    "        '''\n",
    "        if Value not in options:\n",
    "            err_msg = f'{Param} ({dtype.__name__}) must be either '\n",
    "            for n,s in enumerate(options):\n",
    "                if n<len(options)-1: err_msg += f'\"{s}\", '\n",
    "                else: err_msg += f' or \"{s}\" , got %s'\n",
    "            raise ValueError(err_msg % Value)\n",
    "        return Value\n",
    "    \n",
    "    def check_range(self, param0, param1):\n",
    "        \n",
    "        '''\n",
    "        Validate number range.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param0 : tuple(str, float)\n",
    "            A lower bound parameter e.g. (\"name\", -100.)\n",
    "            \n",
    "        param1 : tuple(str, float)\n",
    "            An upper bound parameter e.g. (\"name\", 100.)\n",
    "            \n",
    "        '''\n",
    "        if param0[1] >= param1[1]:\n",
    "            raise ValueError(f\"`{param0[0]}` ({param0[1]}) must be less\"\n",
    "                             f\" than `{param1[0]}` ({param1[1]}).\")\n",
    "            \n",
    "    def check_y_inputs(self, y_proba, y_true=None):\n",
    "        \n",
    "        '''\n",
    "        Validate inputs for calibration models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Predicted probabilities ranges from 0 to 1.\n",
    "            \n",
    "        y_true : array-like, shape (n_samples,), default=None\n",
    "            True binary labels (0/1).\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_proba : ndarray shape (n_samples,)\n",
    "            Validated probabilities.\n",
    "            \n",
    "        y_true : ndarray shape (n_samples,)\n",
    "            Validated labels. This returns None when `y_ture` is not \n",
    "            provided.\n",
    "            \n",
    "        '''\n",
    "        # Ensure shapes\n",
    "        y_proba = column_or_1d(y_proba)\n",
    "        y_proba = check_array(y_proba, ensure_2d=False, dtype=float)\n",
    "\n",
    "        # Probability range\n",
    "        eps = np.finfo(float).eps\n",
    "        y_proba = np.clip(y_proba, eps, 1 - eps)\n",
    "        \n",
    "        if y_true is not None:\n",
    "            \n",
    "            # Check lengths\n",
    "            y_true = column_or_1d(y_true)\n",
    "            check_consistent_length(y_proba, y_true)\n",
    "\n",
    "            # Check that y_true only contains {0,1}\n",
    "            unique_labels = np.unique(y_true)\n",
    "            if not np.all(np.isin(unique_labels, [0, 1])):\n",
    "                raise ValueError(\"`y_true` must be binary (0 or 1).\")\n",
    "            return y_proba, y_true\n",
    "        \n",
    "        else: return y_proba, None\n",
    "        \n",
    "    def check_class_weight(self, class_weight):\n",
    "        \n",
    "        '''\n",
    "        Validate the `class_weight` parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        class_weight : {dict, \"balanced\"} or None\n",
    "            Weights associated with classes in the form `{label: weight}`.\n",
    "            If set to \"balanced\", the weights are automatically adjusted\n",
    "            inversely proportional to class frequencies.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        class_weight : dict, str or None\n",
    "            Normalized class_weight.\n",
    "            \n",
    "        '''\n",
    "         # Validate the `class_weight` parameter.\n",
    "        if class_weight is None:\n",
    "            return None\n",
    "        elif isinstance(class_weight, str):\n",
    "            args = (\"class_weight\", class_weight, [\"balanced\"], str)\n",
    "            return self.StrOptions(*args)\n",
    "        elif isinstance(class_weight, dict):\n",
    "            return class_weight\n",
    "        else:raise ValueError(f\"Invalid value for `class_weight`: {class_weight}. \"\n",
    "                              f\"Expected dict, 'balanced', or None.\")\n",
    "            \n",
    "    def check_estimator(self, estimator):\n",
    "        \n",
    "        '''\n",
    "        Validate that an estimator follows sklearn interface.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : object\n",
    "            Estimator instance.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If estimator does not implement required methods/attributes.\n",
    "            \n",
    "        '''\n",
    "        for m in [\"get_params\", \"set_params\", \"fit\", \"predict\", \"predict_proba\"]:\n",
    "            if not callable(getattr(estimator, m, None)):\n",
    "                raise ValueError(f\"Estimator missing required method `{m}()`.\")\n",
    "\n",
    "        if estimator.get_params().get(\"fit_intercept\", None) is None:\n",
    "            raise ValueError(\"Estimator missing required parameter \"\n",
    "                             \"`fit_intercept` in get_params().\")\n",
    "        \n",
    "        # Fit model with dummy X and y\n",
    "        N, rnd = 10, np.random.RandomState(0)\n",
    "        estimator.fit(rnd.rand(N).reshape(-1,1), \n",
    "                      rnd.randint(0, 2, size=N))\n",
    "        \n",
    "        for a in [\"coef_\", \"intercept_\"]:\n",
    "            if getattr(estimator, a, None) is None:\n",
    "                raise ValueError(f\"Estimator missing required attribute \"\n",
    "                                 f\"`{attr}` after fit().\")\n",
    "\n",
    "    def check_bins(self, bins, data=None):\n",
    "        \n",
    "        '''\n",
    "        Validate 'bins'\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bins : int, sequence\n",
    "            Number of bins or sequence to divide probabilities.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bins : int, sequence\n",
    "            \n",
    "        '''\n",
    "        # Case 1: bins is integer\n",
    "        if isinstance(bins, int):\n",
    "            if bins <= 0:\n",
    "                raise ValueError(f\"Number of bins must be positive,\"\n",
    "                                 f\" got {bins}.\")\n",
    "\n",
    "        # Case 2: bins is a sequence of bin edges\n",
    "        elif isinstance(bins, (list, np.ndarray)):\n",
    "            \n",
    "            bins = np.asarray(bins)\n",
    "            if bins.ndim != 1:\n",
    "                raise ValueError(\"Bin edges must be a 1D sequence\")\n",
    "            elif not np.all(np.isfinite(bins)):\n",
    "                raise ValueError(\"Bin edges contain non-finite values (NaN/inf)\")\n",
    "            elif not np.all(np.diff(bins) > 0):\n",
    "                raise ValueError(\"Bin edges must be strictly increasing\")\n",
    "            elif len(bins) < 2:\n",
    "                raise ValueError(\"At least two bin edges are required\")\n",
    "            else: pass\n",
    "\n",
    "        else: raise TypeError(\"bins must be int or sequence\")\n",
    "        \n",
    "        return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a671b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxFormatter:\n",
    "    \n",
    "    '''Helper class for consistent matplotlib axis formatting'''\n",
    "\n",
    "    def add_vertical_line(self, ax: plt.Axes, x: float, text: str):\n",
    "        \n",
    "        '''Draw a vertical line with label above it.'''\n",
    "        ax.axvline(x, lw=0.5, color=\"k\", zorder=-1)\n",
    "\n",
    "        # Add a minor tick at the line position\n",
    "        ax.xaxis.set_minor_locator(FixedLocator([x]))\n",
    "        ax.tick_params(axis=\"x\", which=\"minor\", length=3, color=\"k\")\n",
    "\n",
    "        # Add text label above the line\n",
    "        args = (ax.transData, ax.transAxes)\n",
    "        ax.text(x, 1.01, text,  fontsize=13, va='bottom', ha=\"center\", \n",
    "                transform=transforms.blended_transform_factory(*args))\n",
    "\n",
    "    def add_axis_labels(self, ax: plt.Axes, ylabel: str, xlabel: str):\n",
    "        \n",
    "        '''Set axis labels and background style'''\n",
    "        ax.set_ylabel(ylabel, fontsize=13)\n",
    "        ax.set_xlabel(xlabel, fontsize=13)\n",
    "        ax.set_facecolor(\"white\")\n",
    "        ax.patch.set_alpha(0)\n",
    "\n",
    "    def add_axis_text(self, ax: plt.Axes, ytext: str, xtext: str):\n",
    "        \n",
    "        '''Add text annotations to the ends of the axes.'''\n",
    "        args = (ax.transAxes, ax.transAxes)\n",
    "        transform = transforms.blended_transform_factory(*args)\n",
    "        ax.text(0, 1.01, ytext, fontsize=13, va='bottom', \n",
    "                ha=\"center\", transform=transform)\n",
    "        ax.text(1.01, 0, xtext, fontsize=13, va='center', \n",
    "                ha=\"left\", transform=transform)\n",
    "        \n",
    "    def add_calibration_line(self, ax: plt.Axes, x: np.ndarray):\n",
    "        \n",
    "        '''Add a reference 'perfect calibration' dashed line.'''\n",
    "        eps = np.finfo(float).eps\n",
    "        ax.plot(x, x, ls=\"--\", lw=1, color=\"grey\", \n",
    "                label=\"Perfect Calibration\")\n",
    "        \n",
    "    def add_annotation(self, ax: plt.Axes, text: str, loc: int):\n",
    "        \n",
    "        '''Add annotation'''\n",
    "        bottom, top = ax.get_ylim()\n",
    "        left, right = ax.get_xlim()\n",
    "        \n",
    "        # Positional arguments\n",
    "        args = {1: (text, (left , top)),\n",
    "                2: (text, (right, top)), \n",
    "                3: (text, (right, bottom)),\n",
    "                4: (text, (left , bottom))}\n",
    "        \n",
    "        # Keyword arguments\n",
    "        kwargs = {1 : dict(ha=\"left\" , va=\"top\"   , xytext=( 5,-5)),\n",
    "                  2 : dict(ha=\"right\", va=\"top\"   , xytext=(-5,-5)),\n",
    "                  3 : dict(ha=\"right\", va=\"bottom\", xytext=(-5, 5)),\n",
    "                  4 : dict(ha=\"left\" , va=\"bottom\", xytext=( 5, 5))}\n",
    "        \n",
    "        kwds = dict(textcoords='offset points', fontsize=12)\n",
    "        kwds.update(kwargs[loc])\n",
    "        ax.annotate(*args[loc], **kwds)\n",
    "\n",
    "    def format_axis(self, ax: plt.Axes):\n",
    "        \n",
    "        '''Apply axis formatting (ticks, spines, and percent scale)'''\n",
    "        percent_formatter = ticker.PercentFormatter(xmax=1)\n",
    "        ax.xaxis.set_major_formatter(percent_formatter)\n",
    "        ax.yaxis.set_major_formatter(percent_formatter)\n",
    "        ax.yaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "        ax.xaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "        ax.tick_params(axis=\"both\", labelsize=10.5)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    def format_legend(self, ax: plt.Axes):\n",
    "        \n",
    "        '''Format legend for clean appearance'''\n",
    "        ax.legend(edgecolor=\"none\", borderaxespad=0.2, \n",
    "                  markerscale=1.5, columnspacing=0.3, \n",
    "                  handletextpad=0.5, loc=\"best\",\n",
    "                  prop=dict(size=12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class calibration_metrics(ValidateParams, AxFormatter):\n",
    "    \n",
    "    '''\n",
    "    Evaluate and visualize calibration metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    calibrator : object\n",
    "        Fitted calibrator that must have method `predict()`.\n",
    "        \n",
    "    bins : int or sequence, default=10\n",
    "        Number of bins or sequence to divide probabilities.\n",
    "        \n",
    "    alpha : float, default=0.05\n",
    "        Confidence interval significance level (two-tailed).\n",
    "        Assumes normally distributed errors.\n",
    "        \n",
    "    strategy : {'uniform', 'normal', 'linear'}, default='linear'\n",
    "        Strategy for determining bin edges.\n",
    "\n",
    "    '''\n",
    "    strategies = ['uniform', 'normal', 'linear']\n",
    "    colors = [\"#1B9CFC\", \"#FC427B\"]\n",
    "    methods = {\"ABM_BetaCal\": \"Beta (ABM)\",\n",
    "               \"AB_BetaCal\" : \"Beta (AB)\",\n",
    "               \"AM_BetaCal\" : \"Beta (AM)\", \n",
    "               \"Sigmoid_Cal\": \"Logistic\"}\n",
    "    \n",
    "    def __init__(self, calibrator, bins=10, alpha=0.05, strategy=\"linear\"):\n",
    "        \n",
    "        # Validate all parameters\n",
    "        self.bins = self.check_bins(bins)\n",
    "        self.alpha = self.Interval(\"alpha\", alpha, float, 0., 1., \"both\")\n",
    "        self.strategy = self.StrOptions('strategy', strategy, self.strategies, str)\n",
    "        self.z = norm.ppf(1 - self.alpha/2)\n",
    "        \n",
    "        # Check if fit() was called\n",
    "        if not callable(getattr(calibrator, \"predict\", None)):\n",
    "            raise ValueError(f\"Estimator missing required method `predict()`.\")\n",
    "        else: self.calibrator = calibrator\n",
    "        \n",
    "        # Get readable calibrator name\n",
    "        name = calibrator.__class__.__name__\n",
    "        if name == \"BetaCalibration\":\n",
    "            name = calibrator.calibrator_.__class__.__name__\n",
    "        self.name = self.methods.get(name, name)\n",
    "            \n",
    "    def fit(self, y_true, y_proba):\n",
    "    \n",
    "        '''\n",
    "        Fit model to determine bin edges.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array-like of shape (n_samples,)\n",
    "            True binary labels.\n",
    "            \n",
    "        y_proba : array-like of shape (n_samples,)\n",
    "            Uncalibrated probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted instance with bin edges.\n",
    "        \n",
    "        '''\n",
    "        y_calib = self.calibrator.predict(y_proba)\n",
    "    \n",
    "        if not isinstance(self.bins, int):    \n",
    "            self.bin_edges = self.bins    \n",
    "        elif self.strategy in [\"uniform\", \"normal\"]:\n",
    "            kwargs = dict(n_quantiles=100, random_state=0,\n",
    "                          output_distribution=self.strategy, \n",
    "                          subsample=10000, copy=True)\n",
    "            transformer = QuantileTransformer(**kwargs)\n",
    "            \n",
    "            t = transformer.fit_transform(y_calib.reshape(-1,1))\n",
    "            t = np.histogram(t, bins=self.bins)[1].reshape(-1,1)\n",
    "            self.bin_edges = transformer.inverse_transform(t).ravel()\n",
    "        else:\n",
    "            amin, amax = np.percentile(y_calib, q=[0,100])\n",
    "            self.bin_edges = np.linspace(amin, amax, self.bins)            \n",
    "\n",
    "        return self\n",
    "\n",
    "    def reliability_curve(self, y_true, y_proba, ax=None):\n",
    "\n",
    "        '''\n",
    "        Plot reliability evaluation metric. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            True binary labels.\n",
    "\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Uncalibrated probability estimates.\n",
    "\n",
    "        ax : matplotlib.axes.Axes, default=None\n",
    "            Predefined Matplotlib axis. If None, a new figure and axis \n",
    "            are created.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ax : matplotlib.axes.Axes\n",
    "            The axis containing the calibration plot.\n",
    "\n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"bin_edges\"])\n",
    "        \n",
    "        # Setup axis and configuration.\n",
    "        if ax is None: ax = plt.subplots(figsize=(6.5,4.5))[1] \n",
    "            \n",
    "        # Compute per-bin confidence statistics\n",
    "        output = self.compute_confidence(y_true, y_proba)\n",
    "        \n",
    "        # Plot estimated probabilities\n",
    "        ax.plot(output.est_means, output.act_means, \n",
    "                color=self.colors[1], lw=1, ms=5, marker=\"o\", \n",
    "                label=f'Estimates - {self.name}')\n",
    "   \n",
    "        # Confidence Interval (by Bin)\n",
    "        label = f'{1-self.alpha:.1%} CI ({output.n_bins:.0f} bins)'\n",
    "        ax.errorbar(output.est_means, output.est_means, elinewidth=1,\n",
    "                    yerr=self.z * output.est_error, capsize=5, \n",
    "                    fmt=\"none\", ecolor=self.colors[1], label=label)\n",
    "\n",
    "        # Add perfectly calibrated line\n",
    "        self.add_calibration_line(ax, output.est_means)\n",
    "        \n",
    "        # Expected Calibrated Error, MCE (Maximum Calibration Error) \n",
    "        delta = np.abs(output.act_means - output.est_means)\n",
    "        ece, mce = sum(output.weights * delta), max(delta)\n",
    "        self.add_annotation(ax, f\"ECE = {ece:.2%}, MCE = {mce:.2%}\", 3)\n",
    "        \n",
    "        # Axis formatting\n",
    "        self.add_axis_labels(ax, 'Empirical Probability', 'Calibrated Probability')\n",
    "        self.format_axis(ax)\n",
    "        self.format_legend(ax)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def calibration_curve(self, y_true, y_proba, ax=None):\n",
    "\n",
    "        '''\n",
    "        Plot calibration evaluation metric.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            True binary labels.\n",
    "\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Uncalibrated probability estimates.\n",
    "\n",
    "        ax : matplotlib.axes.Axes, default=None\n",
    "            Predefined Matplotlib axis. If None, a new figure and axis \n",
    "            are created.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ax : matplotlib.axes.Axes\n",
    "            The axis containing the calibration plot.\n",
    "\n",
    "        '''\n",
    "        # Setup axis\n",
    "        if ax is None: ax = plt.subplots(figsize=(6.5,4.5))[1] \n",
    "        \n",
    "        # Scatter points for each class\n",
    "        for n in np.unique(y_true):\n",
    "            x = np.sort(y_proba[y_true==n])\n",
    "            y = self.calibrator.predict(x)\n",
    "            ax.scatter(x, y, color=self.colors[n], marker=\"o\", \n",
    "                       s=30, alpha=0.5, label=f\"Class {n}\")\n",
    "            \n",
    "        # Plot calibration curve\n",
    "        x = np.linspace(0, 1, 101)\n",
    "        y = self.calibrator.predict(x)\n",
    "        ax.plot(x, y, lw=0.5, color=\"b\", label=self.name)\n",
    "        \n",
    "        # Add perfectly calibrated line\n",
    "        self.add_calibration_line(ax, x)\n",
    "\n",
    "        # Mark midpoint (m)\n",
    "        m = getattr(self.calibrator.params_, \"m\", None)\n",
    "        if m is not None: self.add_vertical_line(ax, m, f\"m = {m:.2g}\")\n",
    "\n",
    "        # Axis formatting\n",
    "        self.add_axis_text(ax, r\"$\\sigma(x)$\", \"x\") \n",
    "        self.add_axis_labels(ax, \"Calibrated Probability\", \"Raw Probability\")\n",
    "        self.format_axis(ax)\n",
    "        self.format_legend(ax)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def compute_confidence(self, y_true, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Compute per-bin confidence statistics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            True binary labels.\n",
    "\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Uncalibrated probability estimates.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Output : namedtuple\n",
    "            act_means : np.ndarray\n",
    "            est_means : np.ndarray\n",
    "            est_error : np.ndarray\n",
    "            counts    : np.ndarray\n",
    "            weights   : np.ndarray\n",
    "            n_bins    : int\n",
    "        \n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"bin_edges\"])\n",
    "        \n",
    "        # Calculate group indices from calibrated probabilities\n",
    "        y_calib = self.calibrator.predict(y_proba)\n",
    "        indices = np.digitize(y_calib, bins=self.bin_edges, right=True)\n",
    "        unq,cnt = np.unique(indices, return_counts=True)\n",
    "    \n",
    "        # Calculate empirical accuray and mean confidence\n",
    "        act_means, est_means, est_error = [], [], []\n",
    "        for k in unq:\n",
    "            act_means.append(np.mean(y_true[indices==k]))\n",
    "            est_means.append(np.mean(y_calib[indices==k]))\n",
    "            est_error.append(np.std(y_calib[indices==k]))\n",
    "\n",
    "        # Store results\n",
    "        data = dict(act_means=np.array(act_means), \n",
    "                    est_means=np.array(est_means),\n",
    "                    est_error=np.array(est_error),\n",
    "                    counts=cnt, \n",
    "                    weights=cnt/sum(cnt),\n",
    "                    n_bins=len(cnt))\n",
    "        return namedtuple(\"Output\", data.keys())(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateLoss:\n",
    "    \n",
    "    '''\n",
    "    Utility class to evaluate model performance before and after \n",
    "    calibration.\n",
    "\n",
    "    Metrics:\n",
    "        - Brier score\n",
    "        - Log loss\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gini(self, y_true, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Compute Gini coefficient from ROC AUC.\n",
    "        '''\n",
    "        return 2 * roc_auc_score(y_true, y_proba) - 1\n",
    "    \n",
    "    def _ece(self, y_true, y_proba, n_bins=20):\n",
    "        \n",
    "        '''\n",
    "        Compute Expected Calibration Error (ECE). ECE approximates error \n",
    "        by partitioning predictions into M equally-spaced bins (similar \n",
    "        to the reliability diagrams) and taking a weighted average of the \n",
    "        bins' accuracy/confidence difference.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like of shape (n_samples,)\n",
    "            Predicted probabilities before calibration.\n",
    "            \n",
    "        y_true : array-like of shape (n_samples,)\n",
    "            Ground truth binary labels.\n",
    "\n",
    "        n_bins : int, default=20\n",
    "            Number of bins to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ece : float\n",
    "            Expected Calibration Error\n",
    "            \n",
    "        '''\n",
    "        # Bin edges and indices\n",
    "        bin_edges = np.linspace(0, 1, n_bins + 1) \n",
    "        indices = np.digitize(y_proba, bin_edges, right=True)\n",
    "\n",
    "        ece = 0.0\n",
    "        for m in np.unique(indices):\n",
    "            in_bin = indices == m\n",
    "            acc  = np.mean(y_true[in_bin])\n",
    "            conf = np.mean(y_proba[in_bin])\n",
    "            ece += np.mean(in_bin) * np.abs(acc - conf)\n",
    "            \n",
    "        return ece\n",
    "\n",
    "    def evaluate(self, y_proba, y_true):\n",
    "        \n",
    "        '''\n",
    "        Evaluate loss metrics before and after calibration.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like of shape (n_samples,)\n",
    "            Predicted probabilities before calibration.\n",
    "            \n",
    "        y_true : array-like of shape (n_samples,)\n",
    "            Ground truth binary labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        losses : namedtuple\n",
    "            Pre and post calibration losses/errors i.e. Brier score, \n",
    "            log-loss, and Expected Calibration Error (ECE).\n",
    "            \n",
    "        '''\n",
    "        a, b = (y_true, y_proba), (y_true, self.predict(y_proba))\n",
    "        losses = {\"brier_score\": [float(brier_score_loss(*a)), \n",
    "                                  float(brier_score_loss(*b))],\n",
    "                  \"log_loss\"   : [float(log_loss(*a)), \n",
    "                                  float(log_loss(*b))],\n",
    "                  \"ece_score\"  : [float(self._ece(*a)), \n",
    "                                  float(self._ece(*b))]}\n",
    "        \n",
    "        return namedtuple(\"Losses\", losses.keys())(**losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABM_BetaCal(BaseEstimator, RegressorMixin, ValidateParams, EvaluateLoss):\n",
    "    \n",
    "    '''\n",
    "    Beta regression model with three parameters introduced in \n",
    "    Kull, M., Silva Filho, T.M. and Flach, P. (2017).\n",
    "    Beta calibration: a well-founded and easily implemented \n",
    "    improvement on logistic calibration for binary classifiers.\n",
    "    AISTATS 2017.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    This implementation is adapted from the `betacal` Python library \n",
    "    (https://github.com/dirmeier/betacal) with modifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object, default=None\n",
    "        Base estimator used for calibration. It must be compatible \n",
    "        with the scikit-learn regressor interface (supporting parameter \n",
    "        management, fitting, prediction, and probability estimation).  \n",
    "        If None, defaults to LogisticRegression with parameters \n",
    "        `C=1e12`, and `fit_intercept=True`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    params_ : namedtuple\n",
    "        Model parameters:\n",
    "        - a : coefficient for log(p)\n",
    "        - b : coefficient for log(1 - p)\n",
    "        - c : intercept\n",
    "        - m : midpoint\n",
    "        \n",
    "    calibrator_ : sklearn.linear_model.LogisticRegression\n",
    "        Internal logistic regression used to train the model.\n",
    "        \n",
    "    losses_ : namedtuple\n",
    "        Pre and post calibration losses (Brier score and log-loss).\n",
    "\n",
    "    '''\n",
    "    def __init__(self, estimator=None):\n",
    "        \n",
    "        if estimator is None:\n",
    "            kwargs = dict(C=1e12, fit_intercept=True)\n",
    "            self.estimator = LogisticRegression(**kwargs)\n",
    "        else:\n",
    "            self.check_estimator(estimator)\n",
    "            estimator.set_params(**{\"fit_intercept\":True})\n",
    "            self.estimator = estimator\n",
    "        \n",
    "    def __transform__(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Transform probabilities into 2D-array for logistic regression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X : array-like, shape (n_samples, 2)\n",
    "            Transformed X.\n",
    "        \n",
    "        '''\n",
    "        eps = np.finfo(float).eps\n",
    "        X = np.clip(y_proba, eps, 1 - eps).reshape(-1,1)\n",
    "        X = np.log(np.hstack((X, 1.0 - X)))\n",
    "        X[:, 1] *= -1\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, y_proba, y_true, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model using y_proba, y_true as training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            Training data.\n",
    "\n",
    "        sample_weight : array-like, shape = (n_samples,), default=None \n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of self.\n",
    "            \n",
    "        '''\n",
    "        # Validate inputs\n",
    "        y_proba, y = self.check_y_inputs(y_proba, y_true)\n",
    "        X = self.__transform__(y_proba)\n",
    "     \n",
    "        # Initial model fitting\n",
    "        self.calibrator_ = clone(self.estimator).fit(X, y, sample_weight)\n",
    "        a, b = self.calibrator_.coef_.ravel()\n",
    "        self.index = [0,1]\n",
    "        \n",
    "        # Adjust if coefficients are negative\n",
    "        if a < 0:\n",
    "            self.index = [1]\n",
    "            self.calibrator_.fit(X[:,self.index], y, sample_weight)\n",
    "            a, b = 0, self.calibrator_.coef_.ravel()[0]\n",
    "        elif b < 0:\n",
    "            self.index = [0]\n",
    "            self.calibrator_.fit(X[:,self.index], y, sample_weight)\n",
    "            a, b = self.calibrator_.coef_.ravel()[0], 0\n",
    "\n",
    "        c = self.calibrator_.intercept_[0]\n",
    "        m = minimize_scalar(lambda m : np.abs(b*np.log(1.-m)-a*np.log(m)-c),\n",
    "                            bounds=[0, 1], method='Bounded').x\n",
    "       \n",
    "        # Store related parameters\n",
    "        values = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"m\": float(m)}\n",
    "        self.params_ = namedtuple(\"Parameters\", values.keys())(**values)\n",
    "        \n",
    "        # Losses before and after calibration\n",
    "        self.losses_ = self.evaluate(y_proba, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Predict new values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_calib : array, shape (n_samples,)\n",
    "            The predicted values.\n",
    "            \n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"params_\", \"calibrator_\"])\n",
    "\n",
    "        # Validate inputs\n",
    "        y_proba, _ = self.check_y_inputs(y_proba, None)\n",
    "        X = self.__transform__(y_proba)\n",
    "        y_calib = self.calibrator_.predict_proba(X[:,self.index])[:,1]\n",
    "        \n",
    "        return y_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56740425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AM_BetaCal(BaseEstimator, RegressorMixin, ValidateParams, EvaluateLoss):\n",
    "    \n",
    "    '''\n",
    "    Beta regression model with two parameters (a and m, fixing a = b)\n",
    "    introduced in Kull, M., Silva Filho, T.M. and Flach, P. Beta \n",
    "    calibration:a well-founded and easily implemented improvement on \n",
    "    logistic calibration for binary classifiers. AISTATS 2017.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    This implementation is adapted from the `betacal` Python library \n",
    "    (https://github.com/dirmeier/betacal) with modifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object, default=None\n",
    "        Base estimator used for calibration. It must be compatible \n",
    "        with the scikit-learn regressor interface (supporting parameter \n",
    "        management, fitting, prediction, and probability estimation).  \n",
    "        If None, defaults to LogisticRegression with parameters \n",
    "        `C=1e12`, and `fit_intercept=True`.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    params_ : namedtuple\n",
    "        Model parameters:\n",
    "        - a : coefficient for log(p / (1 - p))\n",
    "        - b : a\n",
    "        - c : intercept\n",
    "        - m : midpoint\n",
    "        \n",
    "    calibrator_ : sklearn.linear_model.LogisticRegression\n",
    "        Internal logistic regression used to train the model.\n",
    "        \n",
    "    losses_ : namedtuple\n",
    "        Pre and post calibration losses (Brier score and log-loss).\n",
    "\n",
    "    '''\n",
    "    def __init__(self, estimator=None):\n",
    "        \n",
    "        if estimator is None:\n",
    "            kwargs = dict(C=1e12, fit_intercept=True)\n",
    "            self.estimator = LogisticRegression(**kwargs)\n",
    "        else:\n",
    "            self.check_estimator(estimator)\n",
    "            estimator.set_params(**{\"fit_intercept\":True})\n",
    "            self.estimator = estimator\n",
    "        \n",
    "    def __transform__(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Transform probabilities into 2D-array for logistic regression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X : array-like, shape (n_samples, 1)\n",
    "            Transformed X.\n",
    "        \n",
    "        '''\n",
    "        eps = np.finfo(float).eps\n",
    "        X = np.clip(y_proba, eps, 1 - eps).reshape(-1,1)\n",
    "        X = np.log(X / (1. - X))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, y_proba, y_true, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model using y_proba, y_true as training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            Training data.\n",
    "\n",
    "        sample_weight : array-like, shape = (n_samples,), default=None \n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of self.\n",
    "            \n",
    "        '''\n",
    "        # Validate inputs\n",
    "        y_proba, y = self.check_y_inputs(y_proba, y_true)\n",
    "        X = self.__transform__(y_proba)\n",
    "     \n",
    "        # Initial model fitting\n",
    "        self.calibrator_ = clone(self.estimator).fit(X, y, sample_weight)\n",
    "        a = self.calibrator_.coef_.ravel()[0]\n",
    "        b = a \n",
    "        c = self.calibrator_.intercept_[0]  \n",
    "        m = 1. / (1. + np.exp(c / a)) \n",
    "\n",
    "        # Store related parameters\n",
    "        values = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"m\": float(m)}\n",
    "        self.params_ = namedtuple(\"Parameters\", values.keys())(**values)\n",
    "        \n",
    "        # Losses before and after calibration\n",
    "        self.losses_ = self.evaluate(y_proba, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Predict new values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_calib : array, shape (n_samples,)\n",
    "            The predicted values.\n",
    "            \n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"params_\", \"calibrator_\"])\n",
    "            \n",
    "        # Validate inputs\n",
    "        y_proba, _ = self.check_y_inputs(y_proba, None)\n",
    "        X = self.__transform__(y_proba)\n",
    "        y_calib = self.calibrator_.predict_proba(X)[:,1]\n",
    "        \n",
    "        return y_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AB_BetaCal(BaseEstimator, RegressorMixin, ValidateParams, EvaluateLoss):\n",
    "    \n",
    "    '''\n",
    "    Beta regression model with two parameters (a and b, fixing m = 0.5)\n",
    "    introduced in Kull, M., Silva Filho, T.M. and Flach, P. Beta \n",
    "    calibration: a well-founded and easily implemented improvement on \n",
    "    logistic calibration for binary classifiers. AISTATS 2017.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    This implementation is adapted from the `betacal` Python library \n",
    "    (https://github.com/dirmeier/betacal) with modifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object, default=None\n",
    "        Base estimator used for calibration. It must be compatible \n",
    "        with the scikit-learn regressor interface (supporting parameter \n",
    "        management, fitting, prediction, and probability estimation).  \n",
    "        If None, defaults to LogisticRegression with parameters \n",
    "        `C=1e12`, and `fit_intercept=True`.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    params_ : namedtuple\n",
    "        Model parameters:\n",
    "        - a : coefficient for log(p) \n",
    "        - b : coefficient for log(1-p) \n",
    "        - c : 0.\n",
    "        - m : midpoint\n",
    "                \n",
    "    calibrator_ : sklearn.linear_model.LogisticRegression\n",
    "        Internal logistic regression used to train the model.\n",
    "        \n",
    "    losses_ : namedtuple\n",
    "        Pre and post calibration losses (Brier score and log-loss).\n",
    "\n",
    "    '''\n",
    "    def __init__(self, estimator=None):\n",
    "        \n",
    "        if estimator is None:\n",
    "            kwargs = dict(C=1e12, fit_intercept=False)\n",
    "            self.estimator = LogisticRegression(**kwargs)\n",
    "        else:\n",
    "            self.check_estimator(estimator)\n",
    "            estimator.set_params(**{\"fit_intercept\":False})\n",
    "            self.estimator = estimator\n",
    "            \n",
    "    def __transform__(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Transform probabilities into 2D-array for logistic regression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X : array-like, shape (n_samples, 2)\n",
    "            Transformed X.\n",
    "        \n",
    "        '''\n",
    "        eps = np.finfo(float).eps\n",
    "        X = np.clip(y_proba, eps, 1 - eps).reshape(-1,1)\n",
    "        X = np.log(np.hstack((X, 1. - X)))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, y_proba, y_true, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model using y_proba, y_true as training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            Training data.\n",
    "\n",
    "        sample_weight : array-like, shape = (n_samples,), default=None \n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of self.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        # Validate inputs\n",
    "        y_proba, y = self.check_y_inputs(y_proba, y_true)\n",
    "        X = self.__transform__(y_proba)\n",
    "     \n",
    "        # Initial model fitting\n",
    "        self.calibrator_ = clone(self.estimator).fit(X, y, sample_weight)\n",
    "        a, b = self.calibrator_.coef_.ravel() * np.r_[1,-1]\n",
    "        c = self.calibrator_.intercept_[0]  \n",
    "        m = minimize_scalar(lambda m : np.abs(a*np.log(m)-b*np.log(1.-m)+c),\n",
    "                            bounds=[0, 1], method='Bounded').x\n",
    "\n",
    "        # Store related parameters\n",
    "        values = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"m\": float(m)}\n",
    "        self.params_ = namedtuple(\"Parameters\", values.keys())(**values)\n",
    "        \n",
    "        # Losses before and after calibration\n",
    "        self.losses_ = self.evaluate(y_proba, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Predict new values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_calib : array, shape (n_samples,)\n",
    "            The predicted values.\n",
    "            \n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"params_\", \"calibrator_\"])\n",
    "            \n",
    "        # Validate inputs\n",
    "        y_proba, _ = self.check_y_inputs(y_proba, None)\n",
    "        X = self.__transform__(y_proba)\n",
    "        y_calib = self.calibrator_.predict_proba(X)[:,1]\n",
    "        \n",
    "        return y_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab41434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid_Cal(BaseEstimator, RegressorMixin, ValidateParams, EvaluateLoss):\n",
    "    \n",
    "    '''\n",
    "    Platt’s scaling is a probability calibration method introduced by \n",
    "    John Platt (1999) to turn raw classifier scores into well\n",
    "    calibrated probabilities. Given a raw score $f(x)$, Platt’s \n",
    "    scaling models the probability of class 1 as: \n",
    "    \n",
    "                    P(y=1|x) = 1 / (1 + exp(A.(x) + B)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object, default=None\n",
    "        Base estimator used for calibration. It must be compatible \n",
    "        with the scikit-learn regressor interface (supporting parameter \n",
    "        management, fitting, prediction, and probability estimation).  \n",
    "        If None, defaults to LogisticRegression with parameters \n",
    "        `C=1e12`, and `fit_intercept=True`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    params_ : namedtuple\n",
    "        Model parameters:\n",
    "        - a : coefficient for p\n",
    "        - b : a\n",
    "        - c : intercept\n",
    "        - m : midpoint\n",
    "        \n",
    "    calib_ : sklearn.linear_model.LogisticRegression\n",
    "        Internal logistic regression used to train the model.\n",
    "        \n",
    "    losses_ : namedtuple\n",
    "        Pre and post calibration losses (Brier score and log-loss).\n",
    "\n",
    "    '''\n",
    "    def __init__(self, estimator=None):\n",
    "        \n",
    "        if estimator is None:\n",
    "            kwargs = dict(C=1e12, fit_intercept=True)\n",
    "            self.estimator = LogisticRegression(**kwargs)\n",
    "        else:\n",
    "            self.check_estimator(estimator)\n",
    "            estimator.set_params(**{\"fit_intercept\":True})\n",
    "            self.estimator = estimator\n",
    "            \n",
    "    def __transform__(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Transform probabilities into 2D-array for logistic regression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X : array-like, shape (n_samples, 2)\n",
    "            Transformed X.\n",
    "        \n",
    "        '''\n",
    "        eps = np.finfo(float).eps\n",
    "        X = np.clip(y_proba, eps, 1 - eps).reshape(-1,1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def fit(self, y_proba, y_true, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model using y_proba, y_true as training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            Training data.\n",
    "            \n",
    "        sample_weight : array-like, shape = (n_samples,), default=None \n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of self.\n",
    "            \n",
    "        '''\n",
    "        # Validate inputs\n",
    "        y_proba, y = self.check_y_inputs(y_proba, y_true)\n",
    "        X = self.__transform__(y_proba)\n",
    "     \n",
    "        # Initial model fitting\n",
    "        self.calibrator_ = clone(self.estimator).fit(X, y, sample_weight)\n",
    "        a = self.calibrator_.coef_.ravel()[0]\n",
    "        b = a\n",
    "        c = self.calibrator_.intercept_[0]  \n",
    "        m = -c/a\n",
    "\n",
    "        # Store related parameters\n",
    "        values = {\"a\": float(a), \"b\": float(b), \"c\": float(c), \"m\": float(m)}\n",
    "        self.params_ = namedtuple(\"Parameters\", values.keys())(**values)\n",
    "        \n",
    "        # Losses before and after calibration\n",
    "        self.losses_ = self.evaluate(y_proba, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Predict new values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_calib : array, shape (n_samples,)\n",
    "            The predicted values.\n",
    "            \n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, [\"params_\", \"calibrator_\"])\n",
    "            \n",
    "        # Validate inputs\n",
    "        y_proba, _ = self.check_y_inputs(y_proba, None)\n",
    "        X = self.__transform__(y_proba)\n",
    "        y_calib = self.calibrator_.predict_proba(X)[:,1]\n",
    "        \n",
    "        return y_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaCalibration(BaseEstimator, RegressorMixin, ValidateParams, \n",
    "                      EvaluateLoss):\n",
    "    \n",
    "    '''\n",
    "    Wrapper class for the three Beta regression models introduced in \n",
    "    Kull, M., Silva Filho, T.M. and Flach, P. Beta calibration: a \n",
    "    well-founded and easily implemented improvement on logistic \n",
    "    calibration for binary classifiers. AISTATS 2017.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    This implementation is adapted from the `betacal` Python library \n",
    "    (https://github.com/dirmeier/betacal) with modifications.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object, default=None\n",
    "        Base estimator used for calibration. It must be compatible \n",
    "        with the scikit-learn regressor interface (supporting parameter \n",
    "        management, fitting, prediction, and probability estimation).  \n",
    "        If None, defaults to LogisticRegression with parameters \n",
    "        `C=1e12`, and `fit_intercept=True`.\n",
    "        \n",
    "    parameters : {\"abm\", \"am\", \"ab\", \"sigmoid\"}, default=\"abm\"\n",
    "        Determines which parameters will be calculated by the model. \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    calibrator_ : sklearn.linear_model.LogisticRegression\n",
    "        Internal calibration model corresponding to the chosen \n",
    "        parameterization.\n",
    "        \n",
    "    params_ : namedtuple\n",
    "        Model parameters, which are a, b, c, and m.\n",
    "\n",
    "    losses_ : namedtuple\n",
    "        Pre and post calibration losses (Brier score and log-loss).\n",
    "\n",
    "    '''\n",
    "    def __init__(self, parameters=\"abm\", estimator=None):\n",
    "        \n",
    "        if estimator is None:\n",
    "            kwargs = dict(C=1e12, fit_intercept=True, max_iter=9988)\n",
    "            self.estimator = LogisticRegression(**kwargs)\n",
    "        else:\n",
    "            self.check_estimator(estimator)\n",
    "            self.estimator = estimator.set_params(**{\"fit_intercept\":True})\n",
    "        \n",
    "        params = {\"abm\": ABM_BetaCal, \"am\": AM_BetaCal, \n",
    "                  \"ab\": AB_BetaCal , \"sigmoid\": Sigmoid_Cal} \n",
    "        self.parameters = self.StrOptions(\"parameters\", parameters, params.keys())\n",
    "        self.calibrator_ = params[self.parameters](**{\"estimator\":self.estimator})\n",
    "\n",
    "    def fit(self, y_proba, y_true, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model using y_proba, y_true as training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array-like, shape (n_samples,)\n",
    "            Training data.\n",
    "\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "            \n",
    "        sample_weight : array-like, shape = (n_samples,), default=None \n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of self.\n",
    "            \n",
    "        '''\n",
    "        self.calibrator_.fit(y_proba, y_true, sample_weight)\n",
    "        self.params_ = self.calibrator_.params_\n",
    "        self.losses_ = self.calibrator_.losses_\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, y_proba):\n",
    "        \n",
    "        '''\n",
    "        Predict new values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_proba : array-like, shape (n_samples,)\n",
    "            Probability estimates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_calib : array, shape (n_samples,)\n",
    "            The predicted values.\n",
    "\n",
    "        '''\n",
    "        # Check if fit() was called\n",
    "        check_is_fitted(self, \"calibrator_\")\n",
    "        return self.calibrator_.predict(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedLogistic(BaseEstimator, RegressorMixin, ValidateParams):\n",
    "    \n",
    "    '''\n",
    "    Custom implementation of Logistic Regression using scipy's \n",
    "    `minimize` optimizer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    penalty : {\"l1\", \"l2\", \"elasticnet\", None}, default=\"l2\"\n",
    "        Type of regularization applied to the loss function.\n",
    "        Specify the norm of the penalty:\n",
    "    \n",
    "    tol : float, default=1e-4\n",
    "        Tolerance for stopping criteria.\n",
    "\n",
    "    C : float, default=1.0\n",
    "        Inverse of regularization strength; must be a positive float. \n",
    "        Like in support vector machines, smaller values specify \n",
    "        stronger regularization.\n",
    "\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to include an intercept term in the model.\n",
    "\n",
    "    class_weight : dict or \"balanced\" or None, default=None\n",
    "        Weights associated with classes in the form {label: weight}. \n",
    "        If not given, all classes are supposed to have weight one. \n",
    "        \n",
    "    solver : str, default=\"BFGS\"\n",
    "        Algorithm to use in the optimization problem from scipy's \n",
    "        `minimize`, which are {\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \n",
    "        \"Newton-CG\", \"CG\"}.\n",
    "     \n",
    "    max_iter : int, default=1000\n",
    "        Maximum number of iterations for the optimization solver.\n",
    "\n",
    "    l1_ratio : float, default=0.5\n",
    "        ElasticNet mixing parameter, with `0 <= l1_ratio <= 1`.\n",
    "        - l1_ratio = 1 → L1 penalty\n",
    "        - l1_ratio = 0 → L2 penalty\n",
    "        - 0 < l1_ratio < 1 → combination of L1 and L2 penalties\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    res_ : OptimizeResult\n",
    "        Full optimization result returned by `scipy.optimize.minimize`.\n",
    "        Contains diagnostic information such as final parameters,\n",
    "        convergence status, number of iterations, and gradient.\n",
    "\n",
    "    coef_ : ndarray of shape (n_features,)\n",
    "        Learned coefficients (weights) of the logistic regression model.\n",
    "\n",
    "    intercept_ : ndarray of shape (1,)\n",
    "        Intercept (bias) term added to the decision function.\n",
    "\n",
    "    loss_ : list of float\n",
    "        Sequence of loss values recorded at each optimization step.\n",
    "\n",
    "    params_ : list of ndarray\n",
    "        Sequence of parameter vectors (weights + intercept) evaluated\n",
    "        during optimization.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    methods = ['l1', 'l2', 'elasticnet', None]\n",
    "    solvers = [\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"Newton-CG\", \"CG\"]\n",
    "    \n",
    "    def __init__(self, penalty=\"l2\", tol=1e-4, C=1e4, fit_intercept=True, \n",
    "                 class_weight=None, solver=\"BFGS\", max_iter=1000,  \n",
    "                 l1_ratio=0.5):\n",
    "        \n",
    "        # Validate all parameters\n",
    "        self.penalty = self.StrOptions('penalty', penalty, self.methods, str)\n",
    "        self.tol = self.Interval(\"tol\", tol, float, 0., 1., \"both\")\n",
    "        self.C = self.Interval(\"C\", C, float, 0., None, \"left\")\n",
    "        self.fit_intercept = self.StrOptions('fit_intercept', fit_intercept, [True, False], bool)\n",
    "        self.class_weight = self.check_class_weight(class_weight)\n",
    "        self.solver = self.StrOptions('solver', solver, self.solvers, str)\n",
    "        self.max_iter = self.Interval(\"max_iter\", max_iter, int, 1, None, \"left\")\n",
    "        self.l1_ratio = self.Interval(\"l1_ratio\", l1_ratio, float, 0., 1., \"both\")\n",
    "        self.xy_kwargs = dict(accept_sparse=True, dtype=float, \n",
    "                              ensure_2d=True, y_numeric=True)\n",
    "        \n",
    "        # Attributes\n",
    "        self.loss_ = list()\n",
    "        self.params_ = list()\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \n",
    "        '''\n",
    "        Fit the model according to the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Training vector, where `n_samples` is the number of samples \n",
    "            and `n_features` is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target vector relative to X.\n",
    "\n",
    "        sample_weight : array-like of shape (n_samples,) default=None\n",
    "            Array of weights that are assigned to individual samples.\n",
    "            If not provided, then each sample is given unit weight.\n",
    "            \n",
    "        References\n",
    "        ----------\n",
    "        [1] https://docs.scipy.org/doc/scipy/reference/generated/scipy.\n",
    "            optimize.minimize.html\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            Fitted estimator.\n",
    "        \n",
    "        '''\n",
    "        # Validate inputs\n",
    "        X, y = check_X_y(X, y, **self.xy_kwargs)\n",
    "        self.n_features_ = X.shape[1]\n",
    "        if type_of_target(y) != \"binary\":\n",
    "            raise ValueError(\"This estimator only supports binary targets.\")\n",
    "        \n",
    "        # Initialize sample weights\n",
    "        sample_weight = _check_sample_weight(sample_weight, X)\n",
    "\n",
    "        # Default parameters\n",
    "        params = np.zeros(self.n_features_ + self.fit_intercept)\n",
    "        \n",
    "        # Apply class_weight if provided\n",
    "        if isinstance(self.class_weight, str):\n",
    "            classes = np.unique(y)\n",
    "            weights = compute_class_weight(self.class_weight, \n",
    "                                           classes=classes, y=y)\n",
    "            weights = dict(zip(classes, weights))\n",
    "        elif isinstance(self.class_weight, dict):\n",
    "            weights = self.class_weight\n",
    "        else: weights = None\n",
    "            \n",
    "        # `class_weight` x `sample_weight`\n",
    "        if isinstance(weights, dict):\n",
    "            sample_weight *= np.where(y==0, weights[0], weights[1])\n",
    " \n",
    "        # Optimizer\n",
    "        res = minimize(fun=lambda params: self.__optimize__(params, X, y, sample_weight)[0],\n",
    "                       x0=np.zeros(len(params)),\n",
    "                       jac=lambda params: self.__optimize__(params, X, y, sample_weight)[1],\n",
    "                       method=self.solver, \n",
    "                       tol=self.tol,\n",
    "                       options={\"maxiter\":self.max_iter})\n",
    "        \n",
    "        self.coef_ = res.x[:-1]\n",
    "        self.intercept_ = np.r_[res.x[-1]]\n",
    "        self.n_iter_ = res.nit\n",
    "        self.res_ = res\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __optimize__(self, params, X, y, sample_weight):\n",
    "        \n",
    "        '''\n",
    "        Compute loss and gradient for optimization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : ndarray of shape (n_features + 1,)\n",
    "            Flattened array of weights and bias.\n",
    "\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            True labels.\n",
    "            \n",
    "        sample_weight : array-like of shape (n_samples,) \n",
    "            Array of weights that are assigned to individual samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : float\n",
    "            Logistic loss with regularization.\n",
    "\n",
    "        gradients : ndarray of shape (n_features + 1,)\n",
    "            Gradient of the loss with respect to weights and bias.\n",
    "        \n",
    "        '''\n",
    "        if self.fit_intercept:\n",
    "            w = params[:-1]\n",
    "            b = params[-1]\n",
    "        else:\n",
    "            w = params\n",
    "            b = 0.0\n",
    "\n",
    "        # Compute score\n",
    "        z = X @ w + b\n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        # Loss with penalty\n",
    "        loss = log_loss(y, y_pred, sample_weight=sample_weight) + self.__penalty__(w)\n",
    "        self.loss_.append(loss)\n",
    "\n",
    "        # Compute gradients\n",
    "        error = (y_pred - y) * sample_weight\n",
    "        dw = (X.T @ error) / np.sum(sample_weight) + self.__regularization__(w)\n",
    "        db = np.sum(error) / np.sum(sample_weight) if self.fit_intercept else 0.\n",
    "        \n",
    "        gradients = np.r_[dw, db] if self.fit_intercept else np.r_[dw]\n",
    "        self.params_.append(params)\n",
    "        \n",
    "        return loss, gradients\n",
    "    \n",
    "    def __penalty__(self, w):\n",
    "        \n",
    "        '''\n",
    "        Compute the penalty term for the loss function. The degree of\n",
    "        penalties depends on weights, regularization strength, and \n",
    "        `l1_ratio` (only relevant when \"elasticnet\" is selected)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        w : ndarray of shape (n_features,)\n",
    "            Model weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        penalty : float\n",
    "            Penalty value added to the loss.\n",
    "            \n",
    "        '''\n",
    "        l1 = 1 / self.C * np.sum(np.abs(w))\n",
    "        l2 = 0.5 * 1 / self.C * np.sum(w**2)\n",
    "        \n",
    "        if self.penalty is None:\n",
    "            return 0\n",
    "        elif self.penalty == \"l1\":\n",
    "            return l1 \n",
    "        elif self.penalty == \"l2\":\n",
    "            return l2\n",
    "        elif self.penalty == \"elasticnet\":\n",
    "            return self.l1_ratio * l1 + (1 - self.l1_ratio) * l2\n",
    "    \n",
    "    def __regularization__(self, w):\n",
    "        \n",
    "        '''\n",
    "        Compute the regularization term for the gradient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        w : ndarray of shape (n_features,)\n",
    "            Model weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        grad_penalty : ndarray of shape (n_features,)\n",
    "            The array of penalties with respect to `w`. \n",
    "            \n",
    "        '''\n",
    "        l1 = 1 / self.C * np.sign(w)\n",
    "        l2 = 1 / self.C * w\n",
    "        \n",
    "        if self.penalty is None: \n",
    "            return 0\n",
    "        elif self.penalty == \"l1\":\n",
    "            return l1\n",
    "        elif self.penalty == \"l2\":\n",
    "            return l2\n",
    "        elif self.penalty == \"elasticnet\":\n",
    "            return self.l1_ratio * l1 + (1 - self.l1_ratio) * l2\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Predict class probabilities for input samples.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_proba : ndarray of shape (n_samples, 2)\n",
    "            Probability estimates for the negative and positive class.\n",
    "        \n",
    "        '''\n",
    "        X = check_X_y(X, np.ones(len(X)), **self.xy_kwargs)[0]\n",
    "        z = X @ self.coef_ + self.intercept_\n",
    "        y_proba = 1 / (1 + np.exp(-z))\n",
    "        return np.vstack([1 - y_proba, y_proba]).T\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \n",
    "        '''\n",
    "        Predict binary labels for input samples.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input samples.\n",
    "\n",
    "        threshold : float, default=0.5\n",
    "            Threshold used to assign class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray of shape (n_samples,)\n",
    "            Predicted class labels (0 or 1).\n",
    "            \n",
    "        '''\n",
    "        y_proba = self.predict_proba(X)\n",
    "        return np.where(y_proba >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a44e5f-e667-4692-b241-f21df8bf0593",
   "metadata": {},
   "source": [
    "### <font color=\"green\" size=5> Make classification data </font>\n",
    "\n",
    "Generate a random n-class classification problem. [**`make_classification`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ef5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.datasets import make_classification\n",
    "from BetaCalibrator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2d99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples     = 10000, \n",
    "                           n_features    = 20, \n",
    "                           n_informative = 15, \n",
    "                           n_redundant   = 5, \n",
    "                           random_state  = 0, \n",
    "                           shuffle       = False, \n",
    "                           n_classes     = 2, \n",
    "                           weights       = [0.9, 0.1])\n",
    "\n",
    "X = pd.DataFrame(X, columns=[\"feature_\" + str(n).zfill(2) \n",
    "                             for n in range(1,X.shape[1]+1)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1163b88-abd1-4cad-a4ea-5a1642087949",
   "metadata": {},
   "source": [
    "Split **X** and **y** into random train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9161da0f-ada0-46fd-a68b-258c9c103d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_kwds = {\"test_size\"   : 0.3,\n",
    "            \"random_state\": 0, \n",
    "            \"shuffle\"     : True}\n",
    "X_train, X_test, y_train, y_test = tts(X, y, **tts_kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8ba4c-3b94-4d3e-b1d8-336c84e26d3e",
   "metadata": {},
   "source": [
    "Train model with **train** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2499e33e-f38e-4985-bb85-152fd075e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rf(**{\"random_state\": 0, \n",
    "            \"n_estimators\": 200, \n",
    "            \"n_jobs\"      : -1, \n",
    "            \"class_weight\": \"balanced\", \n",
    "            \"max_depth\"   : 7, \n",
    "            \"max_features\": \"sqrt\"})\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "y_test_proba  = clf.predict_proba(X_test )[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2285260-ecdb-4002-ad4e-ed7148d43bdc",
   "metadata": {},
   "source": [
    "### <font color=\"green\" size=5> Calibration of probability </font>\n",
    "\n",
    "The purpose of [`calibration`](https://scikit-learn.org/stable/modules/calibration.html)  is to improve estimated probabilities, which can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a **`predict_proba`** value close to 0.8, approx. 80% actually belong to the positive class.\n",
    "\n",
    "**<font color=\"black\" size=3> What is Beta Calibration? </font>**\n",
    "\n",
    "Beta Calibration is an advanced post-processing calibration technique that transforms a model’s predicted probabilities into better-calibrated probabilities. It was introduced by Kull, Filho, and Flach (2017) as a generalization of Platt’s scaling, providing more flexibility by modeling the calibrated probabilities with a Beta distribution rather than a simple logistic function.\n",
    "\n",
    "- Platt scaling $$p=\\sigma(a⋅s+c)$$\n",
    "- Beta Calibration $$p=\\sigma(a⋅\\log(s)+b⋅\\log(1−s)+c)$$\n",
    "\n",
    "where:\n",
    "- $s$ is an uncalibrated model score $s\\in[0,1]$\n",
    "- $a,b,c$ are parameters to be learned\n",
    "- $\\sigma(x) = \\frac{1}{1+e^{-x}}$ is the logistic function\n",
    "\n",
    "---\n",
    "\n",
    "**<font color=\"black\" size=3> Type of Beta Calibrations </font>**\n",
    "\n",
    "1. ABM (Full Beta Calibration)\n",
    "    - All three parameters are used: $a,b,c$\n",
    "    - Most flexible and can correct both skew and miscalibration near 0 or 1\n",
    "    - a &rightarrow; Coefficient for $\\log(s)$\n",
    "    - b &rightarrow; Coefficient for $\\log(1-s)$\n",
    "    - c &rightarrow; Intercept\n",
    "    - $p=\\sigma(a⋅\\log(s)+b⋅\\log(1−s)+c)$\n",
    "\n",
    "2. AM (A + Intercept)\n",
    "    - Only $a$ and $c$ are learned while $b$ is fixed\n",
    "    - a &rightarrow; Coefficient for $\\log(\\frac{1}{(1 -s)})$\n",
    "    - b &rightarrow; a\n",
    "    - c &rightarrow; Intercept\n",
    "    - $p=\\sigma(a⋅\\log(\\frac{1}{(1 -s)})+c)$\n",
    "    \n",
    "3. AB (No Intercept)\n",
    "    - Only $a$ and $b$ are learned while $c$ is 0.\n",
    "    - a &rightarrow; Coefficient for $\\log(s)$\n",
    "    - b &rightarrow; Coefficient for $\\log(1-s)$\n",
    "    - c &rightarrow; 0.\n",
    "    - $p=\\sigma(a⋅\\log(s)+b⋅\\log(1-s))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6567b13",
   "metadata": {},
   "source": [
    "**<font color=\"blue\" size=4> Example 1: Beta Calibration using ABM Method </font>**\n",
    "\n",
    "The following example demonstrates how to apply Beta Calibration using the \"abm\" method, where parameters _`a`_, _`b`_, _`c`_, and _`m`_ are learned from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99ce79",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; border-left:5px solid #f39c12; background-color:#fff8e1;\">\n",
    "    <b>Note:</b> The calibration model must be fitted on a dataset that is <b>independent</b> from the one used to train the classifier.<br> Using the same samples can lead to <b>biased calibration</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9af082",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 1. Model Training and Calibration </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3224212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BetaCalibration(estimator=LogisticRegression(C=1000000000000.0, max_iter=9988))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BetaCalibration</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BetaCalibration(estimator=LogisticRegression(C=1000000000000.0, max_iter=9988))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1000000000000.0, max_iter=9988)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1000000000000.0, max_iter=9988)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BetaCalibration(estimator=LogisticRegression(C=1000000000000.0, max_iter=9988))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Beta Calibration model using \"abm\" method\n",
    "abm_model = BetaCalibration(\"abm\")\n",
    "\n",
    "# Fit the calibrator using predicted probabilities and true labels\n",
    "abm_model.fit(y_test_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1e2c8",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 2. Calibrator Parameters  </font>**\n",
    "\n",
    "The Beta Calibration model estimates four parameters:\n",
    "_`a`_, _`b`_, _`c`_, and _`m`_, where _`m`_ represents the inflection point of the calibration curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c861660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameters(a=0.0, b=9.450428924205298, c=-7.004744714052171, m=0.5234631677981934)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abm_model.params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f5b5d",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 3. Pre- and Post-Calibration Performance </font>**\n",
    "\n",
    "You can view the Brier score and log-loss before and after calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510f5c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Losses(brier_score=[0.08803823472690542, 0.03780771047320076], log_loss=[0.33208460489803954, 0.14057148029726368], ece_score=[0.21338749414070945, 0.006999031753615902])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abm_model.losses_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a32ef",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; border-left:5px solid #3498db; background-color:#ebf5fb;\">\n",
    "    <b>Info:</b> Lower post-calibration losses indicate that the calibrated probabilities better reflect true likelihoods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaabe07",
   "metadata": {},
   "source": [
    "Use the line below to <b>evaluate the calibration performance</b> of your model on other data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5faab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Losses(brier_score=[0.07360912907420548, 0.01824820895188812], log_loss=[0.2972692421638243, 0.07281354711137139], ece_score=[0.22327042460781915, 0.018488142178215337])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abm_model.evaluate(y_train_proba, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f1014",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 4. Visualization and interpretation</font>**\n",
    "\n",
    "Use the line below to <b>visualize calibration performance</b> using both calibration and reliability curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b70b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BetaCalibrator.calibration_metrics at 0x27b1b58e220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the calibration metrics class\n",
    "visualize = calibration_metrics(abm_model, alpha=0.05, bins=10, strategy=\"linear\")\n",
    "visualize.fit(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7bbeaf",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 4.1 Calibration Curve </font>** \n",
    "\n",
    "The calibration curve shows how closely the predicted probabilities match the actual outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9c4624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = visualize.calibration_curve(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeea570",
   "metadata": {},
   "source": [
    "This produces the following calibration curve:\n",
    "\n",
    "- The **dotted diagonal line** represents **perfect calibration**, where predicted probabilities match actual outcomes.\n",
    "- The **blue line** shows the calibrated curve.\n",
    "- The **points** represent the actual class outcomes.\n",
    "- The **vertical line** marks **the inflection point** — where the calibration function transitions most steeply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790db6f5",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    border-left: 5px solid #00b894;\n",
    "    background-color: #ecfdf5;\n",
    "    padding: 10px 15px;\n",
    "    border-radius: 5px;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "\">\n",
    "💡 <b>Tip:</b>\n",
    "To focus on a single class, apply a mask to your data before plotting:\n",
    "<pre><code>self.plot(y_proba[y_true==1], y_true[y_true==1])</code></pre>\n",
    "This displays the calibration curve only for samples belonging to <b>Class 1</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ac036",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 4.2 Interpretation of Calibration Curve </font>**\n",
    "\n",
    "- When the calibrated curve is **below** the diagonal, the model is **overconfident** (it predicts probabilities that are too high).\n",
    "- When it is **above** the diagonal, the model is **underconfident**.\n",
    "- _`m`_ indicates the point of steepest change, acting as the inflection point that shapes the calibration mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b718c3",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 4.3 Reliability Curve </font>** \n",
    "\n",
    "The reliability curve provides a statistical summary of calibration error across bins, including confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f400ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = visualize.reliability_curve(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8231b0b",
   "metadata": {},
   "source": [
    "This produces the following reliability curve:\n",
    "\n",
    "- The **dotted diagonal line** represents **perfect calibration**, where calibrated probabilities match empirical outcomes.\n",
    "- The **pink markers** represents empirical probabilities (observed outcomes) versus predicted probabilities.\n",
    "- The **error bars** denotes the confidence intervals across bins.\n",
    "- **ECE (Expected Calibration Error)** and **MCE (Maximum Calibration Error)** summarize the overall and worst-case deviations from perfect calibration, respectively.\n",
    "\n",
    "Mathematically:\n",
    "$$ECE =\\sum_{i=1}^{N} \\frac{n_{i}}{N} \\|acc(B_{i}) - conf(B_{i})\\|$$\n",
    "$$MCE= max_{i\\in\\{1,...,K\\}} \\|acc(B_{i}) - conf(B_{i})\\|$$\n",
    "\n",
    "Where:\n",
    "- $K$: number of bins\n",
    "- $n_{i}$: number of samples in bin \n",
    "- $N$: total number of samples\n",
    "- $acc(B_{i})$: average empirical accuracy in bin $i$\n",
    "- $conf(B_{i})$: average predicted confidence in bin $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39561865",
   "metadata": {},
   "source": [
    "**<font color=\"black\" size=4> 4.4 Interpretation of Reliability Curve </font>**\n",
    "\n",
    "- When the reliability curve is **below** the diagonal, the calibrated model **underestimates** probabilities. \n",
    "- When it is **above** the diagonal, the model **overestimates** probabilities.\n",
    "- The error bars show the variability or uncertainty (confidence interval) of the empirical estimates across bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da078013",
   "metadata": {},
   "source": [
    "**<font color=\"blue\" size=4> Example 2: Comparison of all Beta-calibration methods </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27b7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Calibration models\n",
    "methods = {\"Beta (ABM)\": BetaCalibration(\"abm\"),\n",
    "           \"Beta (AB)\" : BetaCalibration(\"ab\"),\n",
    "           \"Beta (AM)\" : BetaCalibration(\"am\"), \n",
    "           \"Logistic\"  : BetaCalibration(\"sigmoid\")}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Fit all calibrators and record parameters and metrics\n",
    "for name, calibrator in methods.items():\n",
    "    \n",
    "    # Fit calibrator on test set\n",
    "    calibrator.fit(y_test_proba, y_test)\n",
    "    \n",
    "    # Record parameters (a, b, c, m)\n",
    "    params = calibrator.params_._asdict()\n",
    "    data = {\"Method\": name, **params}\n",
    "    \n",
    "    # Evaluate performance on Test and Train sets\n",
    "    loss_test  = calibrator.losses_._asdict()\n",
    "    loss_train = calibrator.evaluate(y_train_proba, y_train)._asdict()\n",
    "\n",
    "    # Add to result list\n",
    "    data.update({f\"{k}_Test\": v[1] for k,v in loss_test.items()})\n",
    "    data.update({f\"{k}_Train\": v[1] for k,v in loss_train.items()})\n",
    "    results.append(data)\n",
    "\n",
    "# MultiIndex columns\n",
    "columns = [(\"Method\", \"\") if key == \"Method\" else\n",
    "           (\"Parameters\", key) if len(key)==1 else\n",
    "           (\"_\".join(key.split(\"_\")[:-1]), key.split(\"_\")[-1])\n",
    "           for key in data.keys()]\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "df = df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77da56de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Parameters</th>\n",
       "      <th colspan=\"2\" halign=\"left\">brier_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ece_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">log_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beta (ABM)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.450</td>\n",
       "      <td>-7.005</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beta (AB)</td>\n",
       "      <td>4.091</td>\n",
       "      <td>3.631</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beta (AM)</td>\n",
       "      <td>3.861</td>\n",
       "      <td>3.861</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>16.882</td>\n",
       "      <td>16.882</td>\n",
       "      <td>-8.768</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method Parameters                     brier_score       ece_score  \\\n",
       "                       a      b      c     m        Test Train      Test   \n",
       "0  Beta (ABM)      0.000  9.450 -7.005 0.523       0.038 0.018     0.007   \n",
       "1   Beta (AB)      4.091  3.631  0.000 0.521       0.038 0.019     0.014   \n",
       "2   Beta (AM)      3.861  3.861 -0.359 0.523       0.038 0.019     0.011   \n",
       "3    Logistic     16.882 16.882 -8.768 0.519       0.038 0.019     0.009   \n",
       "\n",
       "        log_loss        \n",
       "  Train     Test Train  \n",
       "0 0.018    0.141 0.073  \n",
       "1 0.023    0.145 0.075  \n",
       "2 0.022    0.145 0.075  \n",
       "3 0.021    0.142 0.074  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a18d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
